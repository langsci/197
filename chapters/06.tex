\chapter{Grammaticality intuitions}

The use of grammaticality intuitions as empirical data in linguistic theory is controversial, and there is an ongoing debate regarding their utility (\citealt{CulicoverJackendoff2010,FFerreira2005,GibsonFedorenko2010,GibsonFedorenko2013,SprouseAlmeida2013}). Conventionally, grammaticality is distinguished from acceptability (\citealt{Schütze2016,Sprouse2007}). Grammaticality is said to relate to “competence”, i.e. knowledge of an underlying grammar, the isolated “narrow” faculty of language. Acceptability relates to intuitions regarding whether sentences are “acceptable” (i.e. something a speaker could say and/or understand), and these intuitions are presumed to derive from grammaticality intuitions plus other “performance” factors: memory limitations, semantic plausibility, interpreter age, emotional state, etc. 

  There are problems with the grammaticality/acceptability distinction. For the distinction to make any sense, one has to presuppose some concept of a grammar and an isolated syntax module. There is also the issue of whether it is possible empirically to distinguish grammaticality intuitions from acceptability intuitions. Because of these problems we deliberately conflate grammaticality and acceptability in the o/el approach. In the o/el model, production and interpretation are associated with trajectories in a state space, and meanings are experiences of those trajectories. Grammaticality intuitions cannot be intuitions \textit{about objects}, in this view. Instead, grammaticality intuitions must be experiences of trajectories. The question then becomes: what determines the quality of those experiences? 

  We propose below that grammaticality/acceptability intuitions arise from the experience of system coherence. As shown earlier, for a coherent system, the width of its power spectrum is narrow and remains at a constant frequency: coherence is required for stability. Grammaticality/acceptability intuitions can thus be understood in relation to the coherence of all systems for all excited φ configurations in a trajectory, which we call \textit{grammatical coherence}. In this chapter, we develop a heuristic test of grammatical coherence which involves assessing whether a trajectory can be reiterated, apply the concept of coherence to intuitions regarding constituency, and examine some electrophysiological manifestations of coherence. 

\section{Problems with grammaticality}

The conventional concepts of grammaticality and acceptability are easy targets for critique. We elaborate several such critiques here: grammaticality and grammar can only be defined circularly; intuitions are inherently dynamic but often treated as static; the mechanisms behind grammaticality intuitions conflate producer and interpreter states; intuitions have often been associated with only sentences or phrases, but they are unavoidably associated with context as well.

\subsection{Grammar-grammaticality circularity}

The concepts of \textit{a grammar} and \textit{a grammatical sentence} form a tautological relation with grammaticality intuitions. One view of a grammar evokes the \textit{grammar-as-theory} motif:

The grammar of a language can be viewed as a theory of the structure of this language. Any scientific theory is based on a certain finite set of observations and, by establishing general laws stated in terms of certain hypothetical constructs, it attempts to account for observations, to show how they are interrelated, and to predict an indefinite number of new phenomena. \citep[113]{Chomsky1956}.

  The above view fails to recognize that there is no theory-free observation nor theory-neutral conception of “the structure”. The observations themselves are always theoretical constructs. Conceptual metaphors and image schemas unavoidably predetermine our understanding of the observations. One might take a \textit{so what?} attitude to this critique—perhaps the point that observations are never theory-free is obvious and inescapable and we can shrug it off and get on with our lives. Even so, the above passage begs the question of \textit{what} the observations \textit{are}. We should always attend to the process of constructing our understanding of the observations, because the theory and observations are one and the same.

  Whereas \textit{grammar-as-theory} views the grammar itself as the theory, \textit{grammar-as-device} views a grammar as an object that is studied by theory. This serves to reify the notion of a grammar: grammars become entities which we study:

Syntactic investigation of a given language has as its goal the construction of a grammar that can be viewed as a device of some sort for producing the sentences of the language under analysis. …The ultimate outcome of these investigations should be a theory of linguistic structure in which the descriptive devices utilized in particular grammars are presented and studied abstractly, with no specific reference to particular languages. \citep[11]{Chomsky1957}.

A fairly reasonable expectation, for a scientific discipline, is that a grammar must explain behavior:

…a grammar must reflect and explain the ability of a speaker to produce and understand new sentences which may be much longer than any he has previously heard. \citep[124]{Chomsky1956}.

  But the above uses of \textit{grammar} beg the question of what “the sentences of the language” and “new sentences” \textit{are}. How do we know which sentences are grammatical, and which ones are not? Sometimes the distinction is presupposed to be evident:

…a device of some sort (called a grammar) for generating all and-only-the sentences of a language, which we have assumed were somehow given in advance \citep[85]{Chomsky1957}

Suppose that for many languages there are certain clear cases of grammatical sentences and certain clear cases of ungrammatical sequences \citep[113]{Chomsky1956}.

…we may assume for this discussion that certain sequences of phonemes are definitely sentences, and that certain other sequences are definitely non-sentences \citep[14]{Chomsky1957}.

Clearly, one would like to provide more grounded definitions, or a method for determining which sentences are and are not in the set of grammatical ones:

One way to test the adequacy of a grammar proposed for L [\textit{a set of sentences}] is to determine whether or not the sequences that it generates are actually grammatical, i.e., acceptable to a native speaker, etc. We can take certain steps towards providing a behavioral criterion for grammaticalness so that this test of adequacy can be carried out. For the purposes of this discussion, however, suppose that we assume intuitive knowledge of the grammatical sentences of English and ask what sort of grammar will be able to do the job of producing these in some effective and illuminating way. We thus face a familiar task of explication of some intuitive concept—in this case, the concept “grammatical in English,” and more generally, the concept “grammatical”. \citep[13]{Chomsky1957}.

  A skeptic might be wary of the “intuitive concept” but nonetheless excited to explore the “behavioral criterion for grammaticalness”. One such criterion involves how sentences are read. Regarding sentences with structures analogous to \REF{ex:6:1} and \REF{ex:6:2} below, \citet{Chomsky1956} identified intonation as one such behavioral criterion:

\ea\label{ex:6:1}
Al ate a sandwich.
\z


\ea\label{ex:6:2}
Sandwich a ate Al
\z

\REF{ex:6:1} will be read by an English speaker with the normal intonation of a sentence of the corpus, while \REF{ex:6:2} will be read with a falling intonation on each word, as will any sequence of unrelated words \citep[114]{Chomsky1956}.

  But the occurrence of list intonation cannot be either a necessary or sufficient criterion for grammaticality: sentence \REF{ex:6:1} \text{can} be uttered with list intonation, and \REF{ex:6:2} \textit{can} be uttered with phrasal intonation. Indeed, plenty of “grammatical” sentences like the one below would probably exhibit a strong tendency to be read with list intonation: 

\ea{A frog a cat a dog chased scared jumped far.}
\z

Some additional prosodic criteria are mentioned in a footnote of \citet{Chomsky1957}, in reference to the utterance below:

\ea
\textit{John enjoyed the book and liked the play}
\z

Such sentences with conjunction crossing constituent boundaries are also, in general, marked by special phonemic features such as extra long pauses (in our example, between "liked" and "the"), contrastive stress and intonation, failure to reduce vowels and drop final consonants in rapid speech, etc. Such features normally hark the reading of non-grammatical strings. \citep[35-36]{Chomsky1957}.

\todo{are there quotations here?}
  Prosodic and other phonological criteria are problematic justifications for grammaticality, at least in the prevailing theoretical frame, because the narrow language faculty is supposed to be isolated from the sensorimotor interfaces. This is likely why such criteria seem to have been abandoned. Or perhaps gestural-motoric aspects of production were subsequently understood to be too complex to serve as useful criteria.   An alternative basis for empirical determination of grammaticality involves associating “grammatical sentences” with “observed sentences”:

Notice that to meet the aims of grammar, given a linguistic theory, it is sufficient to have a partial knowledge of the sentences (i.e., a corpus) of the language, since a linguistic theory will state the relation between the set of observed sentences and the set of grammatical sentences; i.e., it will define "grammatical sentence" in terms of "observed sentence," certain properties of the observed sentences, and certain properties of grammars. \citep[14]{Chomsky1957}.

  This is different from the intonational/phonological criteria, but quite problematic for other reasons. First, what is meant by \textit{observed}? Is an observed sentence a sentence that is produced by a native speaker? Surely observation is not sufficient for grammaticality, since native speakers do produce “ungrammatical” sentences through disfluency mechanisms. And, observation cannot be a necessary condition. In that case, how do we decide which observations and non-observations to include?

It is undeniable that intuition about linguistic form is very useful to the investigator of linguistic form (i.e., grammar). It is also quite clear that the major goal of grammatical theory is to replace this obscure reliance on intuition by some rigorous and objective approach. \citep[93-94]{Chomsky1957}

  Many references to grammaticality show awareness of the tension between the theoretically dichotomous character of grammaticality and the complex, non-dichotomous nature of grammaticality intuitions. Looking at previous excerpt once again:

Suppose that for many languages there are certain clear cases of grammatical sentences and certain clear cases of ungrammatical sequences \citep[113]{Chomsky1956}.

The need to qualify some cases as \textit{clear} cases, implies that some cases are \textit{unclear}. This contradicts the idea that a language can be understood as a set of grammatical sentences. Indeed, Chomsky explicitly refers to degrees of grammaticalness: 

…the resulting sentences are semi-grammatical; the more completely we violate constituent structure by conjunction, the less grammatical is the resulting sentence. This description requires that we generalize the grammatical/ungrammatical dichotomy, developing a notion of degree of grammaticalness \citep[36]{Chomsky1957}.

…we may assume for this discussion that certain sequences of phonemes are definitely sentences, and that certain other sequences are definitely non-sentences. In many intermediate cases we shall be prepared to let the grammar itself decide, when the grammar is set up in the simplest way so that it includes the clear sentences and excludes the clear non-sentences \citep[14]{Chomsky1957}.

  What are these “intermediate cases” that straddle the dichotomy between grammatical and nongrammatical sentences? Ultimately, the problem is that the theoretical constructs—i.e. language as a set (container) of sentences (objects)—requires precise definition of which objects are inside and outside (members and non-members) of the set, but our intuitions about grammaticality cannot be categorized so simply.

  From the above we see that grammaticality is defined relative to a presupposed grammar, and a grammar is defined from observations of grammaticality or tenuous correlates thereof. There is a tension between the discrete intuitions predicted by a grammar and the messiness of actual intuitions. The conventional solution to this problem evolved from “degrees of grammaticalness” into a distinction between grammaticality and acceptability, but the circularity problem has never been resolved. 

\subsection{The non-stationarity of intuitions}

Another major problem with grammaticality is that intuitions are commonly treated as static rather than dynamic. Simply put, our intuitions can change over time and may never be stable. To illustrate, read the sentence below \textit{at a normal pace}, \textit{just one time through}:

    \textit{Either either Dee or Cam knows or Bo knows that Al drinks coffee.}

On first read-through, assuming you did not backtrack, you probably did not reach any clear understanding of the meaning of the sentence. Backtracking is quite natural, and you might have backtracked subconsciously without realizing it. Now, consider the sentence some more, with punctuation to help:

    \textit{Either, either Dee or Cam knows, or Bo knows, that Al drinks coffee.}

  Read the sentence bit by bit, over and over again, until you understand it. Diagram it out with a Venn diagram if you need to. Eventually, it should make some sense. You would never say this sentence (probably), but you can achieve an understanding of it with some effort. Your intuitions about the sentence have changed. This example shows that intuitions are not static, but rather, dynamic, i.e. intuitions change over time.

  Is the time evolution of intuitions predictable? Lets assume that changes such as above are due to the “other factors” (e.g. memory limitations), which are conventionally associated with acceptability. Your early intuitions were muddled by these other factors, and with some effort, the intuition (experience) became stable. Perhaps this is always the pattern: with enough effort, a grammatical sentence which is initially unacceptable becomes acceptable through practice, a satiation effect \citep{Snyder2000}. Lets consider another example:

    \textit{Which coffee\textsubscript{i} does its\textsubscript{i} brewer drink t\textsubscript{i}}?

  The target interpretation here is one in which the pronoun \textit{its} refers to the coffee that the brewer of that same coffee drinks. If you are unfamiliar with this sort of pattern (known as weak crossover) and ignored the coindexation, your initial interpretation most likely assumed some antecedent other than \textit{coffee} for \textit{its}. If so, try to obtain the target weak crossover interpretation. To do this, read the sentence slowly, and when you get to the possessive pronoun \textit{its}, remember that \textit{its} refers to the coffee in question. Imagining a context may help as well:

P1: \textit{Bo brews D-flavored coffee but does not drink it. Al brews C-flavored coffee and drinks it too.} 

P2: \textit{Wait—which coffee does its brewer drink?}

  Hopefully you can achieve the target weak crossover meaning. If so, your interpretation has evolved over time. We cannot really say that the original problem was “memory limitations,” since the sentence is not particularly long and the non-crossover version is quite easy to process. 

  After learning the weak crossover interpretation, does the meaning experience reach a steady state? Read the sentence 20 times, and after each reading take a moment to reflect on what the sentence means. What happens to your intuitions? Most likely they are not the same after the twentieth reading as after the first. Set an alarm for 24 hours from now, or ask someone to remind you tomorrow, and read the sentence (you will probably remember it, so just rehearse it). When you do this, will your intuitions be the same as they are now? Probably not. Furthermore, consider another weak-crossover sentence: 

    \textit{Which brewer\textsubscript{i} does his\textsubscript{i} coffee please t\textsubscript{i}}?

  Your practice with the previous example may help you achieve the crossover interpretation more quickly with this new example, but perhaps not immediately. You may still need to put in some effort. What would happen if you practiced a new weak crossover sentence every day, over the next year? Would the dynamics of your intuitions change? Certainly. Perhaps you could eventually come to judge strong crossover sentences as acceptable (e.g. \textit{Who\textsubscript{i} did he\textsubscript{i} brew coffee for\textsubscript{i}}?). 

  The multi-timescale nature of intuition dynamics, and interactions between intuitions of different utterances, show that intuition changes are not simple approximations to a steady state. The evolution of intuitions is not merely the result of overcoming the influence of the “other factors”. Indeed, there is no reason to assume that intuitions are ever stable. The observation that linguists exhibit different intuitions than non-linguists \citep{Spencer1973} further supports the conclusion that intuitions are inherently unstable in the presence of certain surroundings forces, such as doctoral training in linguistics. It raises the question of whether even more extreme training (e.g. a crossover interpretation bootcamp) can radically alter intuitions. The conventional perspective in which grammaticality intuitions are presumed not to change (because grammars should be static), while acceptability intuitions can change, is ultimately not satisfactory. The problem with partitioning intuitions in this way is that all of the rich dynamics of intuition that do occur, i.e. changes driven by practice, learning, time, context, etc., cannot inform our understanding of “the grammar”.

\subsection{Conflating production and interpretation}

Another problem with notions of grammaticality and acceptability is conflation of production and interpretation. Production involves speaking, signing, and writing; interpretation involves listening, sign-viewing, and reading. We expect these various activities to differ due to differential involvement of sensory and motor systems, but we also expect production and interpretation to interact. In many circumstances speakers monitor their own speech, and conversely hearers rehearse/simulate the utterances they hear. The problem with the conventional approach to understanding intuitions is that it does not provide useful tools for disentangling production and interpretation.

  Lets reflect on a previous example. How do production and interpretation contribute to changes in our intuitions regarding the following sentence? 

    \textit{Either either Dee knows or Cam knows or Bo knows that Al drinks coffee.}

  On first reading, you probably did not understand the sentence. The mechanisms which are normally involved in interpretation created a state which you experienced as somehow abnormal. So, you engaged production mechanisms: you produced the utterance slowly, either in a subvocal rehearsal mode (i.e. with execution gated) or out loud. This may have helped you keep track of various relational meanings evoked in the utterance. On your next attempt at interpretation, you came closer to understanding the sentence. By repeating production and interpretation, you eventually achieved a coherent understanding. Now we ask: does the same process apply to simpler utterances, such as below?

    \textit{Al drinks coffee.}

  This sentence seem to require no effort, as if we interpret it directly, without the need for cycles of interpretation and production. But are we sure that there is nothing production-like involved in this process? Even if no gm-simulation (sub-vocal rehearsal) occurs, could a cs-simulation occur? Moreover, for the more complicated examples, how does an interpretation transition into a production and vice versa?

  The object metaphor and the conventional understanding of a grammar are not well-suited to investigating these questions. The reason is that the object structures created by \textsc{merge} are not readily temporalized, whereas production and interpretation are always temporal. The object metaphor raises many questions regarding what happens in transitions between interpretation and production: do the objects and the connections persist between interpretation and production? How can the structure change over time, unless connections are broken with some sort of \textsc{unmerge} operation? Or, if between interpretation and production we have \textsc{vanish} instead of \textsc{unmerge}, where do the objects go? These absurdities are compounded by the problem that \textsc{merge} is separate from the sensorimotor interfaces. How can \textsc{merge} produce the same output in interpretation and production if, in interpretation, intended meaning relations are initially unavailable and depend on the structure to be built by \textsc{merge?} 

\subsection{The construction of text and context}

Another facet of the debate about grammaticality intuitions centers on the role of context (\citealt{Bolinger1965,Keller2000,Schütze2016}). From the o/el perspective, an underlying problem with this debate is presupposition of the conventional conception of context as a container, which reinforces the object metaphor. Those who view grammaticality judgments as unproblematic empirical data either \REF{ex:6:1} see no problem with intuitions about utterances or sentences \textit{out of} context, or \REF{ex:6:2} argue that interpretations of utterances \textit{in} a “default” (idealized, unbiased, etc.) context are useful for theoretical purposes. The alternative view is that grammaticality judgments are problematic because judging an utterance \textit{out of} context can provide misleading observations and thus can result in misguided theories.

  Both viewpoints presuppose the container schema for conceptualizing the relation between sentences and context, as shown below. The sentences are objects (composed of/containing smaller objects, words) and the contexts are containers of the sentences. Hence utterances are spoken \textit{in} a context and we can argue about whether utterances should be analyzed \textit{out of} context.   

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img120.png}
\caption{\missingcaption}
\label{fig:6:1}
\end{figure}
 

  The problem on both sides of the argument is the presupposition of the object/container metaphor, because it reifies the structural conception of language. From the o/el perspective, there is only a state space with dimensions corresponding to system states, forces between systems, a surroundings, and forces from the surroundings—the full system. All aspects of the full system are analytically imposed: we construct them ad hoc to suit our purposes. So, “where” is context in this conceptual model? Context is where we choose it to be. Some aspects of what is conventionally called \textit{context} are systems and corresponding dimensions of the state space; other aspects of context—the ones we choose to ignore or integrate—become surroundings and surroundings forces. We are always free to reconstruct the analysis, reconceptualizing aspects of the surroundings as systems, or reinterpreting systems as surroundings. In other words, context is not a thing, nor a space for things, but rather a choice regarding how to construct an analysis.

\subsection{Competence and performance: objects and use of objects}

A big deal has been made of the distinction between competence and performance in relation to grammaticality \citep{Chomsky1965}. The distinction is an early statement of the notion that there is some core implicit knowledge or mechanism, a narrow faculty of language, the essence of what language is. This core module is \textit{separate from} the sensorimotor interfaces (note the spatial metaphor), which are to blame for deviations of actual production and comprehension from the idealized capacities of the core grammar (competence). In descriptions of the distinction, competence is described as \textit{knowledge}, while performance is not described as knowledge, but rather a “use” of knowledge. Hence the distinction constructs a difference in types: competence is the \textit{objects} themselves, performance is use of those objects:

We thus make a fundamental distinction between competence (the speaker-hearer's knowledge of his language) and performance (the actual use of language in concrete situations) \citep[4]{Chomsky1965}.

  From the o/el perspective, there is no such thing as “knowledge”, construed as objects. Instead, there are system states and surroundings, a state space and forces: there is no \textit{knowledge}, no \textit{objects}, no \textit{merge}. Knowledge and use are not distinguished, because knowledge is not a thing, nor a stuff. Instead, we imagine a multitude of microscopic dimensions, patterns of neural connectivity, neurotransmitter release, ion channels—spatiotemporal order of enormously high dimension. Anything short of that is an analytical simplification; to call it knowledge (competence), and to dissociate it from observations of patterns in time i.e. use of knowledge (performance) misleads us into believing that our categorization of “knowledge” is real. We aim to avoid misleading ourselves in this way.

\section{Grammatical coherence}

In the o/el framework, there is no conventional grammar on which grammaticality intuitions could be based. A new conceptualization of intuitions is needed, one which helps us understand how intuitions emerge and evolve. The approach we take here is to view grammaticality/acceptability intuitions as the experience of coherence or non-coherence of system configurations in interpretation trajectories. For this purpose, we distinguish between \textit{grammatical coherence} and \textit{spectral coherence} of a system. Spectral coherence applies to a single system, and cross-spectral coherence applies to pair of systems. These concepts are important for understanding the pre-stable phase of interpretation. Spectral coherence throughout a e-epoch is also a prerequisite for grammatical coherence, which, as we explore below, is a consequence of whether in interpretation a stable reiterative trajectory emerges.

For a reference point, we construct a canonical interpretation trajectory, and then extend the canonical interpretation trajectory to be reiterative. We then apply the concept of coherence on three scales: e-epochs, utterances, and discourse. One thing to emphasize at the outset of the analysis is that intuitions—just like relational meanings—are experiences which arise from system states. Thus any production or interpretation trajectory is associated with some intuition(s), which may or may not be consciously recognized. We do not specifically address how people communicate intuitions, or how intuitions induce action, although this is certainly a worthwhile line of inquiry.

\subsection{The canonical interpretation trajectory}

In the canonical interpretation trajectory we assume a hearer who hears an utterance produced by a speaker. We impose a number of assumptions on this scenario:

First, the utterance conforms to the canonical production trajectory and is coherent for the speaker. This entails that for the speaker, in the initial epoch of e-organization and in all subsequent epochs, the φ/e states of all excited systems are stationary and have a high degree of coherence. We also assume that if the speaker and hearer were interchanged, the interpreter (formerly the speaker) would experience a coherent interpretation trajectory. 

Second, in the initial state no c-systems are excited. This lets us ignore “top-down” effects which would be manifested as surroundings forces on systems. In general interpretation trajectories these effects can be very important for determining coherence.

Third, we assume that sensory systems (auditory and/or visual) associated with gm-systems from the utterance are veridically perceived by the interpreter: excitation of those sensory systems unambiguously induces c-and s-system excitations. Thus we ignore the possibility of ambiguities arising from multiple gm-domain to c-system mappings (e.g. \textit{there’s a bathroom on the right} vs. \textit{there’s a bad moon on the rise}). Note that we generally have not incorporated sensory systems in our system analyses; instead, we have left sensory system as part of the surroundings. Here we decide to construct the necessary sensory systems, but we do not explicitly model their interactions with c-, s-, g-, and m- systems. Instead we stipulate their influences on the c- and s- systems that are our main focus.

Under the above assumptions, a canonical interpretation trajectory of \textit{Al drinks coffee and tea} is shown below:

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img121.png}
\caption{\missingcaption}
\label{fig:6:2}
\end{figure}

\todo{should this become a proper enumeration?}
(1)
         The trajectory begins with a sequence of c-system and s-system excitations. In the canonical trajectory, only those c-systems associated with the veridically perceived gm-systems in the utterance are excited. In general, surroundings forces will influence the relative timing of when the relevant c-systems become excited, and some c-systems may already be excited from previous utterances or context, including ones which are not associated with the utterance. 

(2)
         Each newly excited c-system forms a cs-resonance. In the canonical trajectory, only the c-systems associated with the utterance couple to s-systems. In general, other c-systems may form cs-resonances, or may already be in resonant configurations with s-systems. Furthermore, the timing of when each cs-resonance forms is underdetermined. The activation of a cs-resonance resonance most likely begins shortly after the relevant sensory systems are activated, but may be further augmented by gm-system activation.

(3)         Some φ configuration stabilizes. \textit{Some} φ configuration, but not necessarily all relevant φ configurations. The stabilization process begins when cs-systems emerge in the previous stage, and the timecourse of cs-system emergence may influence which φ configuration stabilizes first. No particular φ configuration must stabilize first, although we assume that earlier activation of a configuration makes earlier stabilization more likely—in other words, parsing is incremental. 

(4)

         A stable initial e-organization arises. In the canonical scenario, the excited systems are those associated with the φ configuration which stabilized first. In general e-organization can begin before φ-stabilization, but e-stabilization must follow the stabilization of an φ configuration (this is a consequence of our hypothesis that φ-organization can influence e-organization). 

(5)
         The canonical interpretation trajectory leads to a state in which a reiterative trajectory can occur. In the above example, the sequence of epochs (e1…e2) is reiterated, i.e. an alternation between configurations in which {\textbar}Al drinks coffee{\textbar} is attended, and configurations in which {\textbar}Al drinks tea{\textbar} is attended. To distinguish canonical interpretation from canonical production, we analyze the interpretation trajectory as a non-simulative (s-gated and m-gated) regime. In general interpretation trajectories we can relax this assumption and allow for cs-simulation (an m-gated trajectory) or gm-simulation (an e-gated trajectory).

  Reiterative trajectories play an important role in interpretation. Reiteration allows for a trajectory that emerges in interpretation to be less dependent on initial conditions and less dependent on the order of system activation. It also provides a mechanism whereby relatively complex utterances which may be initially unstable can become coherent. Recall that a reiteration is a sequence of unique stable states e\textsubscript{i} … e\textsubscript{n} where e\textsubscript{n} = e\textsubscript{i}. In other words, the system trajectory cycles through a sequence of states. Reiteration is a reconceptualization of “working memory” for relational meaning experiences. An example reiteration of \textit{Bo knows Al drinks coffee} is shown below. After an initial unstable epoch (e0), there is a stable state (e1) in which {\textbar}Bo knows{\textbar} is attended and {\textbar}Al drinks coffee{\textbar} is grounded, then a transition to (e2) in which {\textbar}Al drinks coffee{\textbar} is attended and {\textbar}Bo knows{\textbar} is grounded. This is followed by a transition to (e′\textsubscript{1}), which is equivalent to e1. Hence the trajectory is reiterative.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img122.png}
\caption{\missingcaption}
\label{fig:6:3}
\end{figure}
 

  We remain agnostic regarding whether reorganizations in reiterative trajectories typically occur with cs-selection. This is represented in the potentials above by the empty selection level, and we refer to such trajectories as non-selective, or s-gated. Alternative possibilities are that reiteration is cs-simulative, i.e. the trajectory involves selection of cs-systems without gm-selection, or the reiteration is gm-simulative. It is unclear if our analyses of coherence hinge on this distinction, although we suspect that interpreters are not aware of non-selective reiteration to the same degree that they are aware of cs-selective reiteration.  

  The applicability of reiteration is not restricted to attention-switching between entire clauses. Any sequence of stable configurations can be reiterated. What makes reiteration important is its function as a stabilization and mnemonic mechanism. Consider the example below:  

\ea{Al drinks coffee and tea, and eats granola and eggs.}
\z
  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img123.png}
\caption{\missingcaption}
\label{fig:6:4}
\end{figure}
 

  Interpretation of this utterance involves a reiterative sequence of four φ configurations. In each epoch of the reiteration (e1-e4), a different subset of cs-systems is above ground, while others are grounded. Because there are multiple cs-systems of the same syntactic category, there is a potential for differentiation interference. The grounding of unattended systems mitigates against this interference. However, this comes at a cost: reorganization operations are more complicated, requiring ungrounding promotions and grounding demotions in reorganization. For example, Ê\textsubscript{2} selectively demotes [coffee] to ground and promotes [tea] from ground; Ê\textsubscript{3} demotes [drinks] and [tea] while promoting [eats] and [granola]. Note that we analyze [and]\{CONJ\} as a system which is excited to selection level with each ungrounding promotion, just as in production trajectories.

  The above mechanism generalizes to arbitrarily long utterances, as in \textit{Al drinks coffee and tea, and eats granola and eggs, and Bo drinks whisky and beer, and eats porridge and salad}. How can an interpreter remember the complicated sequence of reorganizations which are required for attending to all of the relational meanings in such an utterance? Of course, an interpreter might not successfully remember such a sequence. But it is possible; and most people would require some practice. We conjecture that reiteration is the mechanism of this “practice” and induces “learning”, i.e. microscale changes which constitute a form of “long-term memory” for the sequence of non-canonical reorganizations. Reiteration with cs-selection, gm-selection, and execution are probably even more effective in this regard: overt execution is the most effective mnemonic technique, subvocal rehearsal (e-gated production) the next most effective, and cs-simulation the least effective.

  The hypothesized learning which reiteration facilitates can be viewed as learning of a sequence of e-reorganizations, which determines an e-space trajectory. There are interesting questions regarding the timescales on which such changes persist, which relate to distinctions between scales of memory (working, short-term, and long-term). The question of how we can learn to remember long sequences warrants further investigation. What is essential here, is that, on the utterance timescale, we do not need to impose any new organizing mechanism for relational meaning experiences. 

\subsection{Grammatical coherence: scales and criteria}

The concept of grammatical coherence can be applied on three scales: the smallest scale involves an e-epoch in which at least one but no more than a few φ configurations are continuously attended. On this epochal scale, coherence only requires that all above-ground cs-systems participate in some stable set of φ configurations. This entails that the cross-spectral coherence for any pair of systems will be relatively high, because frequency-locking is required for stability. We can also apply grammatical coherence to the interpretation of an entire utterance; on the utterance scale, grammatical coherence requires epochal coherence for all epochs in the utterance, as well as a potential for a reiterative simulation of the trajectory. The most relevant scale for analysis of grammaticality/acceptability intuitions is the discourse scale, on which coherence requires utterance coherence and the condition that the attended φ configurations of the interpreter correspond to the attended φ configurations of the producer. Note that we do not require that the sequence of interpreter e-epochs be the same as those of the producer. Hence the following criteria give rise to a coherence hierarchy:

\begin{itemize}
\item 
All excited cs-systems participate in some stable, coherent set of φ configurations.
\item 
A sequence of stable, coherent φ configurations can be reiterated.
\item 
Each φ configuration in the potentially reiterative interpretation trajectory corresponds to a φ configuration in an associated production trajectory.
\end{itemize}

\begin{table}
\begin{tabularx}{.8\textwidth}{XCCC}
\lsptoprule
& (i) & (ii) & (iii)\\
\midrule 
\raggedleft epoch coherence & y &  & \\
\raggedleft utterance coherence & y & y & \\
\raggedleft discourse coherence & y & y & y\\
\lspbottomrule
\end{tabularx}
\caption{\missingcaption}\label{tab:6:1}
\end{table}
  The epoch coherence criterion is that all of the above-ground systems in an e-epoch must participate in at least one stable φ configuration. The states in examples (A)-(D) below fail to meet this criterion. In (A), imagine that an interpreter hears the name \textit{Al}. Without any other cs-system to couple with, [Al]\{N\} does not participate in a stable φ configuration. When an unstable state such as (A) arises, we can imagine two possible continuations of the trajectory. In one, [Al]\{N\} becomes grounded; in the other, additional cs-resonances become excited and a coherent configuration stabilizes. Many pragmatic phenomena can be understood as trajectories in which an utterance evokes an unstable configuration which evolves to a stable configuration when other cs-systems become excited. Often we can construct analyses in which other systems are excited for contextual reasons. Consider the utterance \textit{Al coffee} in (B), which itself is also unstable. However, if we imagine that [drink]\{V\} is also above-ground because the producer and interpreter are discussing who drinks what (e.g. \textit{Al coffee, Bo tea, Cam whisky, Dee beer…}), then the epoch coherence criterion would be met.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img124.png}
\caption{\missingcaption}
\label{fig:6:5}
\end{figure}
 

  In (C) we imagine that an interpreter hears \textit{Al drinks coffee}, and that all cs-systems are above-ground but occupy the same e-level. Because there is no stable φ configuration, the state is non-coherent. However, we do not know whether or not a stable φ configuration \textit{could} evolve from the e configuration in (C), and so it is not the e-organization which makes the configuration unstable, but rather, the absence of a stable φ configuration. In the absence of other forces, we expect that a reorganization to the coherent state in (C′) occurs in conjunction with the emergence of stable φ and e configurations. This example illustrates that coherence derives from a system state, and does not depend on the path taken to arrive at that system state (of course, many paths may not lead to coherence). 

  Example (D) is non-coherent because [tea]\{-N\} is above-ground but does not participate in a stable φ configuration. We note that the underlying cause of the instability is differentiation interference: \{-N\} cannot differentiate into stable [tea]\{-N\} and [coffee]\{-N\} cs-resonances in this configuration. The instability in (D) is typically resolved by grounding the less highly excited system as in (D′). Indeed, we note that the grounding from (D) to (D′) is not necessarily a distinct mechanism from the one which governs e-organization in early production: cs-resonances compete for excitation.

The utterance coherence criterion specifies that there is a \textit{potentially} periodic sequence of epochs (i.e. reiterative trajectory), each of which meets the epochal coherence criterion. It is not required that all epochs which arise in the interpretation of an utterance are coherent, only that an uninterrupted sequence of epochs occurs, through the same re-organization operations which are available for production. It is also not required that the sequence \textit{actually} repeats. We only require that the interpreter system evolves to a state from which re-organization can return the system to the first state in the sequence. Consider the utterance with a parenthetical below. 

  Note that for the sake of providing more compact representations of trajectories which involve multiple φ-epochs, we sometimes represent excited systems on the same e-level, but we nonetheless imagine those systems to occupy distinct e-levels. Note also that we do not require that any systems have selection-level excitation, and therefore canonical reorganizations are unnecessary; thus only selective reorganizations are shown in the example below:

\textit{Al, Bo knows, drinks coffee}.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img125.png}
\caption{\missingcaption}
\label{fig:6:6}
\end{figure}
 

  For utterance coherence, a potentially periodic trajectory of individually coherent epochs must occur for the interpreter. In epoch (e*), a non-coherent state, coherence has not been achieved. However, if subsequently the trajectory (e\textsubscript{1}), (e′\textsubscript{1}) arises, then coherence is achieved: (e′\textsubscript{1}) can evolve to (e\textsubscript{1}) through selective reorganization, and vice versa, in effect shifting attention between two φ configurations. Note that the reorganization from (e*) to (e1) involves a grounding demotion of [Al]\{N\}, which would be the first active cs-system in the canonical trajectory. In the above example, the reiteration that arises does not necessarily match the initial e-organization of the producer, nor does it match the trajectory which occurred for the producer during execution.

  As with epoch coherence, the interpretation trajectory that leads to an utterance-coherent trajectory is not relevant to assessment of coherence: a trajectory in which non-coherent states such as (e*) above occur before the potentially reiterative trajectory. However, coherence intuitions may derive not only from whether a coherent trajectory is ultimately achieved, but also from experience of incoherent states prior to coherence. Thus we should think of utterance coherence intuitions as determined by a trajectory of experiences of states.

  Because utterance coherence does not require any correspondence between producer and interpreter states, it is not very useful for conceptualizing grammaticality intuitions relative to a producer trajectory. Indeed, utterance coherence occurs when the interpreter reaches any coherent reiterative trajectory, regardless of what the producer intended. Thus from the initial state in (e\textsubscript{0}) below, where we assume the speaker intended {\textbar}Bo knows{\textbar} and {\textbar}Al drinks coffee{\textbar} configurations, if the interpreter attends to {\textbar}Al knows{\textbar} and {\textbar}Bo drinks coffee{\textbar} configurations in state (e1) and state (e2), coherence is achieved, despite the producer-interpreter mismatch in φ configurations.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img126.png}
\caption{\missingcaption}
\label{fig:6:7}
\end{figure}
 

  It is important to emphasize that we cannot precisely say “an utterance is coherent”, because coherence is not a property of utterances. Utterance coherence is coherence associated with the timescale of utterances, which can span multiple epochs of attention. We can only say that a coherent, potentially reiterative trajectory occurs in the interpretation of an utterance. Moreover, this does not imply that the trajectory remains coherent: reorganizations might occur, for a number of reasons, which prevent the trajectory from being potentially reiterated.

  Discourse coherence requires the additional condition that φ configurations in the interpreter reiteration correspond to ones that arose during the cs-/gm-selective phase of a production trajectory. Thus unlike epoch and utterance coherence, discourse coherence requires consideration of both interpreter and producer trajectories. Specifically, for each excited φ configuration in the selective phase of a production trajectory, that same φ configuration arises in the interpretation trajectory. Only φ configurations which are excited in selective epochs of the production trajectory are relevant to discourse coherence, because it is possible for a noncanonical production trajectory to visit arbitrary states before and after the states which govern cs-system selection. 

  One important aspect of the correspondence criterion for discourse coherence is that the specific sequence of φ configurations an interpreter experiences need not match the specific sequence of φ configurations which a producer experiences. Imposing this condition results in a stricter version of discourse coherence, but may be hard to apply because producer e-state trajectories can be highly underdetermined for relatively complicated utterances. One possible solution to this problem is to require φ/e reiteration correspondence between producer and interpreter, but this requires us to stipulate that a reiterative producer trajectory always occurs, which is far from obvious.

  Another issue with the discourse coherence criterion is that we have no well-defined notion of “the same” cs-system between a producer and interpreter, at least not when the producer and interpreter are different people. We can ignore this problem or circumvent it by imagining that the interpreter and producer are the same person. This indeed seems to be the case for self-reflective grammaticality/acceptability intuitions that are often used in syntactic theory construction. However, in the more general case where producer and interpreter are not the same person, the concept of discourse coherence requires further assumptions regarding similarity of cs-systems between different individuals.  

\subsection{Incremental organization in interpretation}

How does a stable configuration first arise in interpretation? In the canonical interpretation trajectory, sensory systems exert forces on c-systems and s-systems, which activate them and induce cs-resonances. The canonical trajectory makes the assumption that all cs-resonances were in an active, unexcited state before φ/e organization occurs, as in the trajectories below. But this oversimplification is obviously empirically inadequate. In most cases we expect some organization to arise before production of an utterance has finished.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img127.png}
\caption{\missingcaption}
\label{fig:6:8}
\end{figure}

 

  To expand the empirical scope of our model of interpretation, incremental φ/e organization is necessary. However, the evolution of states during periods in which sensory systems activate cs-systems is generally unconstrained. Below we contrast two highly ordered, memory stack-like trajectories in which systems are incrementally e-organized. In the precedency mapping, each newly activated system becomes excited and occupies the first above-ground level, while previously excited systems are each promoted one level. If the interpreter enters a production regime, the interpretation-production mechanism behaves as a first-in first-out buffer, in a sense. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img128.png}
\caption{\missingcaption}
\label{fig:6:9}
\end{figure}
 

  In the recency mapping, each newly excited system becomes the most highly excited system. In this case the relative excitations must be inverted before a production of the utterance could occur. This would require a new type of reorganization operator, Ê\textsuperscript{{}-1}. This inversion operation is somewhat problematic because it does not seem to occur in other circumstances; it is an ad hoc set of operations that is necessary to convert the recency-based organization to one which is consistent with production.

  In any case, both precedency and recency incremental e-organization are probably too inflexible to be of much general use. Recall our depiction of the chaotic emergence of stable φ/e configurations in production. We might expect something quite similar in interpretation: asymmetries in when individual gm-excitations occur, ambiguities in mappings to c-systems, variation in the growth and competition timecourses of cs-resonances, inhomogeneity in the initial conditions, fluctuations in the surroundings—all of these make highly systematic organization scenarios such as those above quite unlikely.

  A somewhat more realistic picture is one in which φ configurations arise incrementally and exert a strong influence on subsequent e-organization. Meaning relations can form as cs-systems become active, and part of the stabilization process involves excitation of those systems. Hence we expect φ configuration emergence to bias e-organization. For example, in the interpretation trajectory of \textit{Bo knows Al drinks coffee} below, φ configurations are organized as soon as the relevant cs-systems are active. In the subsequent examples, we show the most recently perceived system as grounded in the epoch prior to the one in which it becomes excited.  Hence [knows]\{V\} is active in the epoch (e2), prior to participating in the configuration {\textbar}Bo knows{\textbar} in (e3). Likewise, [Al]\{N\} is active in (e3) and through a selective reorganization becomes excited in (e4). Incrementally organized states bias subsequent reorganizations. For example, the incrementally organized {\textbar}Al drinks{\textbar} state in epoch (e5) biases the system to reorganize to (e6), where {\textbar}Al drinks coffee{\textbar} is excited. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img129.png}
\caption{\missingcaption}
\label{fig:6:10}
\end{figure}
 

  The excitation of [Bo][knows] in (e3) is hypothesized to result from an expectation that a newly active cs-system will enter into a φ configuration with previously excited one, without any intervening φ configurations being organized. In our framework an “expectation” of this sort can be conceptualized as forces which promote coupling of a newly activated cs-system with a previously activated or excited system. We refer to this as the \textit{immediate organization bias}, and consider it to be a guiding principle for incremental organization. Immediate organization explains why utterances such as \textit{Al, Bo knows, drinks coffee} are more difficult to parse: the interpreter cannot couple [Bo]\{N\} with the previously activated/excited system, [Al]\{N\}.

  One empirically desirable consequence of incremental organization and the immediate organization bias is that a previously organized φ configuration can prevent a subsequently excited system from participating in a stable configuration. Consider the following utterance: 

    \textit{Al drinks coffee and tea is brewing.}   

  This example is designed to create a garden path effect. The interpreter may initially understand \textit{tea} as an object of \textit{drinks}, because of the immediate organization bias. A possible interpretation trajectory is shown below. (Note that the trajectory here and in examples to follow depict incremental e-organization, but this is not strictly necessary. The e-organization serves only to facilitate the depiction of the relevant φ configurations). The garden path relational meaning experience of \textit{drinks tea} corresponds to [tea]\{-N\} and [drinks]\{V\} being in a φ configuration, shown in epoch (e3).  However, [brew]\{V\} must -φ couple to a \{-N\} system in order to be coherent. Grounding of the {\textbar}drinks tea{\textbar} configuration prevents [brew]\{V\} and [tea]\{-N\} from being in a stable configuration. The inability of [tea]\{-N\} to couple to both [drinks]\{V\} and [brew]\{V\} is due to the selective reorganization from (e4) to (e5). The interpreter may then become aware of the non-coherence of the state in (e5). This awareness induces a grounding of all systems (e6) and reorganization to the state in (e7). 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img130.png}
\caption{\missingcaption}
\label{fig:6:11}
\end{figure}
 

  On the other hand, the above utterance might not induce a garden path effect. The garden path arises because the selective reorganization Ê\textsubscript{2} grounds only [coffee]\{N\}, as in (A) below. If the selective reorganization Ê\textsubscript{2} occurs as in (B), grounding {\textbar}Al drinks coffee{\textbar}, then [tea]\{N\} does not couple with [drinks]\{V\} and can couple with [brew]\{V\} in (e3).

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img131.png}
\caption{\missingcaption}
\label{fig:6:12}
\end{figure}
 

  The selective reorganization in (B) which grounds all of the cs-systems associated with {\textbar}Al drinks coffee{\textbar} would be more likely to occur in interpretation when the utterance is spoken slowly (or when a comma is present: \textit{Al drinks coffee, and tea is brewing}), and less likely to occur when it is spoken quickly. Thus we can view prosodic manipulations such as boundary-lengthening as a mechanism for diminishing the forces which give rise to the immediate organization bias.

  Our analysis of the garden path repair begs the question of how the interpreter, after becoming aware of the incoherence of the configuration in (e5), knows to reorganize so that [tea]\{N\} and [brew]\{V\} are coupled. This is an important, challenging question, which deserves future attention. In some circumstances, the interpreter does not—without assistance—achieve a coherent reorganization. This suggests that the {\textbar}drink tea{\textbar} system may not be sufficiently decoupled by grounding. The assistance, in everyday conversation, may be in the form of intonation (\textit{Al drinks coffee, … and tea is brewing}). Indeed, even in the textbook example (\textit{the horse raced past the barn fell}), some students who are unfamiliar with the example must be explicitly cued to the coherent meaning (e.g. \textit{the horse that was raced…}) before they are able to achieve a coherent interpretation. 

  Garden path phenomena are a subset of a more general circumstance in which the system trajectory gets trapped in some subspace, preventing the trajectory from evolving to other possible states. In the prototypical garden path, the utterance is non-coherent when the system trajectory enters the trapping region, but more generally, the trapping subspace may be coherent and simply prevents some alternative, potentially coherent trajectory from occurring. This is why ambiguities can be difficult to notice:

  \ea
    {Al drinks soda coffee and tea are my favorites.}
   \z
  In interpretation of the above utterance, immediate organization creates a strong bias for a {\textbar}Al drinks soda{\textbar} configuration to arise. This prevents the alternative coherent interpretation in which the producer means that \textit{Al}, \textit{drinks}, \textit{soda}, \textit{coffee}, and \textit{tea} are their favorite things. The trapping substate here is a cs-resonance of [drinks] with \{V\}, which prevents a [drinks]\{N\} system from being excited. There are many sort of circumstances in which garden path effects can arise (\citealt{FFerreira2005,Pritchett1988}), and comparisons of behavior in these should be provide valuable information regarding incremental organization. 

  It should be noted here that the o/el conception does not gel with certain types of probabilistic models in which representations themselves are considered probabilistic (e.g. \citealt{ChaterManning2006,Manning2003}). The system state is unarguably deterministic: there is one and only one state at any given moment of time, and so we should not reason that there are multiple parses of an utterance, each associated with a probability. Certainly, multiple configurations may be simultaneously active, to varying degrees, but this differs conceptually and implementationally from models in which a unity normalization is applied to construct a probability distribution over states.

  Incremental e-organization is also relevant to understanding why “word salad” utterances such as those below do not typically lead to coherence. In the marginal cases, intonation/punctuation can facilitate coherence when (in fixed order languages) the e-organization deviates from the typical φ-e mapping. We infer from these examples that incremental organization is influenced by learned φ-to-e mappings. What is important about this, from the perspective of our conceptual model, is that interpretation does not necessarily have access to φ relations. Interpreters may need to use e-to-φ mappings, which are inversions of learned φ-to-e mappings, in conjunction with immediate organization. Intonation/punctuation may diminish the influence of immediate organization on incremental organization. 

\ea
  \ea[*]{Al coffee knows drinks Bo.}  
  \ex[*]{Bo drinks Al knows coffee.}
  \ex[*]{Coffee Bo Al drinks knows.}
  \ex[?]{Al Bo knows drinks coffee.}   \biberror{[F0E0?]} {Al—Bo knows—drinks coffee.}
  \ex[?]{Coffee Bo knows Al drinks.}   \biberror{[F0E0?]} {Coffee—Bo knows—Al drinks.}
  \ex[?]{Bo Al drinks coffee knows.}  \biberror{[F0E0?]}  \textsuperscript{? Bo—Al drinks coffee—knows.}
\z
\z

In some cases, there seems to be no amount of intonational/punctuational information which can make the highly abnormal mappings coherent. This suggests that, because of the immediate organization bias, substantial departures from learned φ-e mappings make achieving coherence more difficult. What constitutes a “substantial” departure is an open question.

\subsection{Factors which influence coherence experiences}

It is important to view grammatical coherence as a phenomenon which is associated with an \textit{experience}. More specifically, we experience a trajectory of relational meaning configurations which may or may not be stable. Although our generic hypothesis is that grammaticality/acceptability intuitions reflect these experiences, we have not considered which aspects of the trajectory our intuitions are sensitive to. A comprehensive study of intuitions should consider a wide variety of factors, e.g. the number of simultaneously excited φ configurations, φ configurations in which some systems are active but unexcited, activation of systems which cannot be immediately organized, interference from s-system differentiation, interference from c-system differentiation, the φ of differentiated systems, previously active systems which interfere with the excitation of newly active cs-systems from being organized, etc. 

  Here we focus on interference, which seems to underlie many of the factors listed above in some way or another. The immediate organization bias can also be seen as a mechanism which minimizes interference by stabilizing newly activated systems as soon as possible. Consider the following examples, where in each set of sentences, the (a) examples seem more acceptable than the (b) examples, which are in turn more acceptable than the (c) examples. Furthermore, examples in \REF{ex:6:1} are generally less coherent than their counterparts in \REF{ex:6:2}.  

\begin{table}
\begin{tabularx}{\textwidth}{lQlQ} 
\lsptoprule
& \textbf{center embedding} &  & \textbf{tail recursion}\\
\midrule 
& \textit{I saw…} &  & \textit{I saw…}\\
1a. & \textit{a frog a cat chased.} & 2a. & \textit{a cat who chased a frog.}\\
1b. & \textit{a frog a cat a dog bit, chased.} & 2b. & \textit{a dog who bit a cat, who chased a frog.}\\
1c. & \textit{a frog a cat a dog a bee stung bit chased.} & 2c. & \textit{a bee who stung a dog who bit a cat who chased a frog}\\
&  &  & \\
1a. & \textit{Al, who Bo likes.} & 2a. & \textit{Bo, who likes Al.}\\
1b. & \textit{Al, who Bo, who Cam likes, likes.} & 2b. & \textit{Cam, who likes Bo, who likes Al.}\\
1c. & \textit{Al, who Bo, who Cam, who Dee likes, likes, likes.} & 2c. & \textit{Dee, who likes Cam, who likes Bo, who likes Al.}\\
\lspbottomrule
\end{tabularx}
\caption{\missingcaption}\label{tab:6:2}
\todo[inline]{This should probably not be table. }
\end{table}

  A hypothesized interpretation trajectory for the center embedding of relative clauses in \REF{ex:6:1b} is shown below. Note that we have omitted some intervening epochs in the trajectory to avoid clutter. As we hypothesized earlier the object relative [who]\{\textsc{rel}\} system +φ couples to the relativized \{N\} and -φ couples to a \{V\}. Thus in (e2) a [who]\{\textsc{rel}\} system +φ couples to [Al]\{N\}, and in (e3) a [who]\{\textsc{rel}\} system +φ couples to [Bo]\{N\}. We conceptualize these [who]\{\textsc{rel}\} systems as differentiations of a general \{\textsc{rel}\} system, just like [Al]\{N\} and [Bo]\{N\} are differentiations of \{N\}. Furthermore, we assume that a system is grounded after having participated in its expected φ configuration, unless that system is relativized. Hence we imagine that [I]\{\textsc{PRO}\} and [saw]\{V\} are grounded after (e1) but [Al]\{N\} remains above-ground because it couples with [who]\{\textsc{rel}\} in (e2). Thus \{\textsc{rel}\} systems cause some other system to which they are coupled to remain excited.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img132.png}
\caption{\missingcaption}
\label{fig:6:13}
\end{figure}
 

  Given the above analysis, the first question we ask is: why is \REF{ex:6:1b} less likely to induce a coherent state than \REF{ex:6:1a}? One simple difference is that \REF{ex:6:1b} requires more φ configurations to be simultaneously excited than \REF{ex:6:1a}. This follows from our hypothesis that each [who]\{\textsc{rel}\} system +φ couples to a \{N\} and -φ couples to a \{V\}, along with our assumption that systems coupled to \{\textsc{rel}\} remain excited to participate in a configuration in a subsequent epoch. Having multiple systems of the same class simultaneously excited is potentially problematic because of differentiation interference. In the example there is s-differentiation interference between [Al]\{N\}, [Bo]\{N\}, and [Cam]\{N\}, and between [saw]\{V\} and [likes]\{V\}. There is also c-differentiation interference between [who] systems, and between [likes] systems, although the [likes] subsystems are not simultaneously excited. 

  Interestingly, because of the φ configuration invariance principle, [Al]\{N\} and [Bo]\{N\} must have a φ-distal relation, while [Al]\{N\} and [Cam]\{N\} must have a φ-proximal relation. This follows from our hypotheses regarding role-to-φ patterns for [who]\{\textsc{rel}\}, transitive \{V\}, and agent/patient role \{N\}. Note that we use the term \textit{relation} here rather than configuration because we do not want to imply that the φ pattern arises directly from φ-coupled s-systems. The [Al], [Bo], and [Cam] \{N\} systems must interfere through s-differentiation. Because \REF{ex:6:1b} is substantially worse than \REF{ex:6:1a}, we might guess that the differentiation associated with the proximally φ-related [Al]\{N\} and [Cam]\{N\} induces more interference than the differentiation associated with the distally φ-related [Al]\{N\} and [Bo]\{N\}. This makes a lot of sense given our speculation that \{N\} to \{+N\}/\{-N\} differentiation is relatively unproblematic compared to differentiation within \{+N\} or \{-N\}. In other words, differentiation of a system into two systems with proximal φ may induce more interference than differentiation into two systems with distal φ.

  Perhaps most problematically, there is an epoch of the center embedding interpretation in which a newly activated system cannot be immediately organized. Specifically, in (e2) [Bo]\{N\} is coupled with a \{\textsc{rel}\} system but is not coupled to any lexical \{V\} system in (e3). 

  Indeed, the reason that the tail-recursive utterances in \REF{ex:6:2a}-(2c) are more coherent than their center-embedded counterparts in \REF{ex:6:1a}-(1c) is that each newly activated system can be immediately organized. A possible interpretation trajectory for the tail-recursion of \REF{ex:6:2b} is shown below. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img133.png}
\caption{\missingcaption}
\label{fig:6:14}
\end{figure}
 

  The tail-recursion in \REF{ex:6:2b} does not have any epochs in which a newly activated cs-system does not φ-couple to any previously activated or excited lexical system. In (e2) [Bo]\{N\} couples with [likes]\{V\} before the \{\textsc{rel}\} system couples to [Bo]\{N\}. This contrasts with (e2) of the example \REF{ex:6:1b} with center embedding, where [Bo]\{N\} couples with \{\textsc{rel}\}, and where epochs in which the {\textbar}Cam likes{\textbar} configuration arises intervene before the {\textbar}Bo likes{\textbar} configuration is organized. Furthermore, the {\textbar}likes who{\textbar} configuration in (e2) of the tail recursion trajectory can be grounded in the transition to (e3), which avoids the circumstance where two \{N\}\{\textsc{rel}\} configurations are excited. Loosely speaking, we can attribute the difference in grammaticality intuitions regarding center embedding and tail recursion to difficulty in “keeping things in memory” longer. But more usefully, we see that the difficulty is in keeping an \{N\} excited when it is not φ-coupled with a \{V\}, and that interference with other \{N\} systems may be the underlying cause of the instability. In other words, coupling to \{V\} helps stabilize \{N\} systems and thereby diminishes interference between simultaneously excited \{N\} systems.

  In addition to interference, “contextual” factors, i.e. the state of the surroundings prior to an interpretation, must have an influence on coherence. Consider the utterance below:

  \ea
    {read you a book on modern music?}
\z

This utterance may not readily induce a coherent trajectory. Now, read the list of utterances below:

\ea
\ea {have you a book on modern music?}
\ex {have you a book on ancient music?}
\ex {have you a dictionary of English?}
\ex {want you a dictionary of English?}
\ex {want you a book on ancient music?}
\ex {want you a book on modern music?}
\ex {seen you a book on modern music?}
\ex {seen you a book on ancient music?}
\ex {seen you a dictionary of English?}
\ex {read you a dictionary of English?}
\ex {read you a book on ancient music?}
\ex {read you a book on modern music?}
\z
\z

  The repetition of similar trajectories induces a structural priming effect. The last sentence coheres much more quickly than it did the first time around. Such effects suggest that every time some particular state trajectory occurs, trajectories which require a similar pattern of re-organizations can occur more quickly or with less interference, in interpretation of subsequent utterances. A variety of empirical studies provide evidence that such priming occurs and can have effects on a multi-day timescale (\citealt{BockEtAl2007,VSFerreiraEtAl2006,Nagata1988,Nagata1992,PickeringFerreira2008,RowlandEtAl2012}). We can view such learning as macroscale changes in the forces which regulate φ-to-e mapping: the forces are altered to favor trajectories which are similar to a recently experienced one. There are many interesting questions that one might ask regarding the timescales on which such effects arise.

In contrast to the factors mentioned above, which are generally associated with interference, grammatical coherence does not appear to be as strongly affected by flavors of relational meaning. This can be inferred from the classic \textit{colorless green ideas} example \citep{Chomsky1956}, which does not evoke a strong unacceptability intuition. It does, however, seem to induce an atypical meaning experience.

\ea
    \textit{colorless green ideas sleep furiously}
\z

  The example satisfies the utterance coherence criteria, and there is no reason to posit any particularly strong interference. Any oddness we experience in interpretation of the utterance must therefore derive from some other mechanism. One possible account of the oddness of the experience involves an aggregate effect of weakly excited, weakly interacting c-systems. Recall that we have assumed that interactions between c-systems are generally weak, particularly between lexical c-systems. This assumption is important because strong interactions would compromise flexibility of relational meaning experiences. Yet weak interactions are not the same as no interactions. Indeed, whenever a c-system is excited, many other c-systems must become active. Although we typically omit them from representations, these grounded systems may in the aggregate have an effect on other c-systems. In the picture below we imagine that excitation of [green] induces ground-level excitation of many other c-systems that are associated with [green] (such as [leaf], [grass], [emerald], [apple], etc.), which we label as <green>. The c-systems <green> which are primed by [green] interact weakly with all of the c-systems <colorless> which are primed by [colorless]. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img134.png}
\caption{\missingcaption}
\label{fig:6:15}
\end{figure}
 

  We might furthermore posit that these weak interactions between <green> and <colorless> are somewhat stronger because there is more population overlap/interference between more similar c-systems: c-systems which share a [\textsc{color}] population may interact more strongly. The integrated effect of these interactions may cause the experience of semantic oddness. Although a more detailed understanding of the experience is desirable, we infer it does not result from interference which relates to s-system differentiation.

  Many questions remain open regarding the factors which influence coherence. Although we have only scratched the surface of many issues, the o/el framework provides a useful basis for investigating intuitions as experiences. Importantly, we have rejected the distinction between grammaticality and acceptability. Our analysis of grammatical coherence has focused primarily on how coherence arises in interpretation. Another relevant question is whether coherent trajectories necessarily arise in production. Perhaps an invariant, stable φ configuration arises in both production and interpretation, despite the lack of constraint on initial conditions:

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img135.png}
\caption{\missingcaption}
\label{fig:6:16}
\end{figure}
 

  Production and interpretation are similar in that there are many possible initial states which may evolve toward the same locally invariant φ configuration. In production, various differentiations of e-levels can be used to select cs-systems in different orders (constrained by language-specific φ-e mappings), and yet all of these will evoke the same invariant φ configuration for an interpreter. It is potentially important that both the production and interpretation processes are locally order-increasing. The local concentration of order only occurs when a system has work done it by the surroundings; hence we deduce that both production and interpretation are driven by surroundings forces. Microscopically these forces are presumably manifested from electrochemical gradients that the nervous system works to maintain. In other words, coherence is possible because the microscale system self-organizes to a state in which macroscopic, coherent, ordered patterns arise.

\subsection{Constituency intuitions}

What gives rise to intuitions about constituency, i.e. about how words are grouped, or organized? For example, in the utterance \textit{Al drinks the cold coffee}, we experience an intuition that the words \textit{the cold coffee} constitute a “group” in a way that the words \textit{the cold} do not. In conventional terminology, \textit{the cold coffee} is a constituent, while \textit{the cold} is not a constituent. But what does it mean for words to “be grouped” or to “form a unit” when our conceptual model has no object-like units, and thus no connection or containment of units? Here we show how we can understand these sorts of intuitions through analysis of coherence. Note that viewing constituency as intuitional rather than configurational (i.e. as a particular class of substate) is consistent with the observation that many ordering phenomena are not amenable to constituency-based analysis (\citealt{Langacker1997,Phillips2003}).

  Conventional phrase structure grammars account for constituency intuitions with the connection/containment blend whereby a node contains all of the nodes which are below it and connected directly or indirectly to it. Thus in the schema below, \textit{the cold} is not a constituent because there is no node which contains exactly those syntactic objects—the DP node also contains \textit{coffee}. An additional constraint that non-trivial constituents must correspond to a phrasal node can be imposed, so that terminal elements such as \textit{coffee}, \textit{the}, or \textit{cold} are treated differently. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img136.png}
\caption{\missingcaption}
\label{fig:6:17}
\end{figure}
 

  Our intuitions about constituents are associated with constituency “tests”, some of which are exemplified in the {\tablebelow} (cf. \citealt{Carnie2013,Ouhalla1999} for more comprehensive introductions). Note that these tests are less applicable to verb phrase constituency and some other sorts of constituents; our focus here is on determiner-adjective-noun constituents.

\begin{table}
\begin{tabularx}{\textwidth}{lQQ}
\lsptoprule
\multicolumn{3}{c}{ ψ\textsubscript{0} : \textit{Al drinks the cold coffee}}\\
\multicolumn{1}{c}{ψ\textsubscript{CT}:} & $\varepsilon $\textit{: \textit{the cold coffee}} & $\varepsilon $\textit{: the cold}\\
\midrule 
\raggedleft topicalization & \textbf{The cold coffee}, Al drinks. & \textbf{The cold}, Al drinks coffee.\\
\raggedleft passive & \textbf{The cold coffee} was drunk by Al & \textbf{The cold} was drunk coffee by Al\\
\raggedleft cleft & It is \textbf{the cold coffee} that Al drinks. & It is \textbf{the cold} that Al drinks coffee.\\
\raggedleft pseudocleft & \textbf{The cold coffee} is what Al drinks. & \textbf{The cold} is what Al drinks coffee.\\
\lspbottomrule
\end{tabularx}
\caption{\missingcaption}\label{tab:6:3}
\end{table}
  The general procedure for conducting a constituency test is as follows. First, a candidate set of words $\varepsilon $ is chosen from a base sentence, which in o/el terms is a trajectory ψ\textsubscript{Ref} in which cs-systems associated with $\varepsilon $ are selected. The trajectory is typically comprised of temporally contiguous e-epochs. In o/el terms this means that the trajectory is not interrupted by intervening epochs in which no systems are selected or in which systems other than $\varepsilon $ are selected. Indeed, $\varepsilon $ corresponds to a subpart of the trajectory ψ\textsubscript{Ref} in a subspace of the system. The test is applied by constructing a test sentence (i.e. trajectory) ψ\textsubscript{CT}, according to some particular pattern (e.g. topicalization, passivization, etc.). Grammaticality/acceptability (i.e. coherence) intuitions evoked from the sentence are then assessed. 

  In the case of the topicalization test, ψ\textsubscript{CT} is a trajectory in which the candidate $\varepsilon $ is the first part of the selection phase of ψ\textsubscript{CT}. The coherence intuitions that arise from this procedure for a variety of $\varepsilon $ are represented below. The only $\varepsilon $ which does not induce a relatively non-coherent experience is \textit{the cold coffee}, and according to conventional analyses this is because these words exactly correspond to the words contained in a phrasal node. The conventional analysis of the topicalization test is somewhat unsatisfying because \textit{cold coffee} could also correspond to a phrasal node (depending on various analytic choices) but nonetheless fails the test; further stipulations are necessary to explain why the topicalization pattern cannot apply to \textit{cold coffee}.

\ea
  \ea[]{the cold coffee, Al drinks.}
  \ex[*]{the cold, Al drinks coffee.}
  \ex[*]{the, Al drinks cold coffee}
  \ex[*]{coffee, Al drinks the cold.}
  \ex[*]{cold coffee, Al drinks the.}
  \z
\z

  The o/el re-analysis of constituency begins with a subtle but important point: we do not have intuitions about constituency until we interpret a potential constituent in some other context. More technically, constituency intuitions are \textit{always} associated with the coherence of interpretation of a sub-part of a coherent trajectory, when that subpart is interposed in another trajectory. There are no “constituency intuitions” until we engage in a particular mode of interpretation which involves these trajectory manipulations. This conception not only leads to a new, useful understanding of constituency, based on the notion of coherence, but also explains why constituency intuitions do not accord with patterns of ellipsis and anaphora, which we examine in detail in the next chapter. To illustrate, consider the following reference trajectory ψ\textsubscript{Ref}, of \textit{Al drinks the cold coffee}:

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img137.png}
\caption{\missingcaption}
\label{fig:6:18}
\end{figure}
  

  To assess the constituency intuition for \textit{the cold coffee}, we identify the trajectory of epochs (e3)-(e4), in which [the]\{D\}, [cold]\{ADJ\}, and [coffee]\{N\} are selected. We construct the candidate trajectory $\varepsilon $ by ignoring state space dimensions associated with other non-test systems in (e3)-(e4), i.e. dimensions related to [Al]\{N\} and [drinks]\{V\}. However, we take note of the φ configurations which involve the test systems and non-test systems, since we attempt to integrate these with the constituent test trajectory ψ\textsubscript{CT}. We then construct ψ\textsubscript{CT}, by combining $\varepsilon $ and ψ\textsubscript{CT} according to a desired pattern. This construction procedure predetermines which patterns are suitable (e.g. topicalization, clefting, passive, pseudocleft). Patterns which omit or replace $\varepsilon $ (i.e. ellipsis, anaphora) lead to different intuitions about grouping, as does coordination.

  A test trajectory for topicalization of the candidate \textit{the cold coffee} is shown below. Although immediate organization of [coffee]\{N\} with a \{V\} system is not possible after (e1), excitation of [drinks]\{V\} in (e3) allows [coffee]\{N\} to participate in a φ configuration. We can further hypothesize that after epochs of initial system excitation (e1)-(e3), a coherent reiterative simulation can arise (e3, e3′), in which utterance coherence criteria are met. This analysis entails that constituency intuitions arise from experiencing the achievement of a coherent trajectory, and not necessarily from an experience of the path that is taken to achieve that trajectory.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img138.png}
\caption{\missingcaption}
\label{fig:6:19}
\end{figure}
 

  In contrast to \textit{the cold coffee}, the topicalization test of \textit{the cold} does not lead to a coherent state. The likely reason is shown below: neither [cold]\{ADJ\} nor [the]\{D\} can φ-couple to the lexical \{N\} system [coffee]\{N\}, which is necessary for the expected φ configurations of \{ADJ\} and \{D\}. This begs the question of why in (e4) [the]\{D\} and [cold]\{ADJ\} cannot couple to [coffee]\{N\} and thus give rise to the φ configuration required for coherence. One possibility is that the immediate organization bias is stronger for \{D\} and \{ADJ\} systems than for \{N\} systems. It may be more difficult to maintain \{D\} and \{ADJ\} systems in an unstable state across multiple epochs that it is to maintain \{N\} systems.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img139.png}
\caption{\missingcaption}
\label{fig:6:20}
\end{figure}
 

  Similar accounts can be extended to passivization, pseudocleft and cleft tests, as shown below. The grayed φ configurations with \{D\} and \{ADJ\} are ones which, because of the intervening epochs, are unable to participate in the expected configuration. There may be other reasons why coherence does not occur in these examples. For instance, [cold] might couple to an \{N\} system, which allows for immediate organization with [is]\{\textsc{aux}\} in all three examples. In the cleft, [cold] might couple with [Al]\{N\}, in which case [drinks]\{V\} would have no \{N\} system to +φ couple with because [Al]\{N\} couples with [is]\{\textsc{aux\}.} Thus the immediate organization bias may be an important factor in determining the coherence intuitions associated with constituency.   

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img140.png}
\caption{\missingcaption}
\label{fig:6:21}
\end{figure}
 

  There may be a variety of additional reasons why coherence is not achieved when some particular ψ\textsubscript{CT} is constructed, and a more comprehensive analysis is desirable, one which could predict when coherence is expected in a broader range of constituency tests. The o/el framework nonetheless brings us some clarity by discouraging us from thinking of “constituents” as objects; instead, we reconceptualize constituency as a phenomenon which derives from experiences of coherence or the lack thereof. This requires us to refocus our investigations of constituency phenomena on temporal patterns in interpretation, as opposed to atemporal, abstract structural relations.

\section{Electrophysiological and behavioral manifestations of coherence}

Grammatical coherence on the utterance scale depends on epoch scale coherence, which in turn depends on spectral coherence of c- and s-systems, as well as cross-spectral coherence of systems in a φ configuration. Thus spectral and cross-spectral coherence are the fundamental basis for many aspects of grammaticality intuitions. Here we show how spectral coherence can be related to electrophysiological and behavioral phenomena, specifically focusing on event-related potentials (ERPs) in sentence processing. In order to accomplish this, we first develop a set of linking hypotheses. The coherence phenomena analyzed below occur before the reiterative trajectories which are necessary for grammatical coherence; intuitions regarding grammatical coherence are dependent on and arise subsequently to electrophysiological manifestations of spectral coherence. By means of its emphasis on coherence, the o/el framework provides an alternative vocabulary for understanding various psycholinguistic phenomena.

\subsection{Linking hypotheses for spectral coherence}

One of the major methodological instruments used to study syntactic and conceptual processing is electroencephalography (EEG). EEG measures voltage fluctuations generated by neural spiking in the brain with electrodes placed on the scalp. When EEG signals are aligned to the time at which a stimulus is presented, changes in measured voltages are observed—these are called event-related potentials (ERPs). A number of different ERP patterns have been identified and hypothesized to be associated with syntactic and/or semantic “processing,” a concept which we reinterpret in the current framework. ERPs are commonly given names which refer to when and/or where they are observed, along with whether the observed voltages are negative or positive relative to a reference voltage. For example, researchers have identified an “N400” which is a negative voltage change that occurs in association with semantic processing, a “P600” which is a positive voltage change that occurs in association with syntactic and/or conceptual reanalysis (as in the interpretation of garden path sentences), and an “ELAN” (early left anterior negativity) which is associated with syntactic category processing. 

Here we develop a set of linking hypothesis which allows for the o/el model to generate ERP patterns that are in some ways qualitatively similar to observed ERPs. The key idea behind this approach is that “processing”—a rather vague term—can be reinterpreted more mechanistically as change in the spectral coherence of c- and s-systems, and change in the cross-spectral coherence of cs-systems. For reasons that are made clear below, our focus is on the time-course of such changes as a function of stimuli, rather than their spatial distributions in the brain.

When a single neuron spikes or receives input from other neurons, there is a transmembrane ionic current associated with changes in membrane potential. When the axons of many neurons are oriented similarly in space, the voltage changes associated with individual neurons and synapses combine to create a change in the electrical potential which is measurable at the scalp. Thus the EEG signal is an integration of state changes in many neurons which have a similar orientations. Pyramidal cortical neurons generate most of the cortical EEG signal because these are closest to the scalp (\citealt{FedermeierLaszlo2009,KutasDale1997}). The extracellular fluid and cranium act as low-pass filters on the signal, and hence the spatial resolution of EEG is poor compared to other measurement techniques such as fMRI. However, the time-resolution of EEG is far superior to fMRI and thus it is better-suited to investigating the time-course of syntactic/semantic processing. 

Even in the absence of sensory stimuli, the brain exhibits EEG signals with power at a range of frequencies \citep{Buzsaki2006}. These oscillations are thought to provide a basis for interactions between brain areas, and to facilitate processing of sensory stimuli \citep{FriesEtAl2001,GrayEtAl1989}. Event-related potentials (ERPs) are measured by presenting a stimulus and averaging the stimulus time-locked electrical activity over a large number of trials. The assumptions behind this approach are that the electrical response to the stimulus is of fixed polarity and occurs at a fairly consistent latency relative to stimulus presentation \citep{PennyEtAl2002}. The averaging is necessary because there is typically a large amount of neural activity that is not specific to the stimulus (i.e. noise). There are two main theories on the neural origins of event-related potentials (ERPs): the phase resetting (phase modulation, PM) theory and the evoked response (amplitude modulation, AM) theory \citep{MakeigEtAl2002,PennyEtAl2002,ShahEtAl2004}). In the evoked response view, stimuli “evoke” a neural population response, and EEG power increase is expected in a single trial. Averaging evoked responses over multiple trials amplifies this power increase and thereby produces the ERP pattern. In the phase-resetting model, sensory stimuli induce a phase resetting of EEG rhythms. Under this view, the reason the ERP pattern is observed is due to averaging over trials: in a single trial, no increase in neural activity is expected, but the EEG rhythm will be phase coherent across trials when time-aligned to the stimulus onset; hence averaging over multiple trials is necessary to observe an ERP, which reflects phase-coherence. Another possibility is that both phase-modulation and amplitude modulation influence ERPs \citep{PennyEtAl2002,ShahEtAl2004}. For current purposes we assume that both of these effects contribute to coherence. 

  Many language-related ERP studies investigate sentence processing by comparing ERPs between conditions in which some relevant syntactic or semantic aspect(s) of sentences are varied. The comparisons are made by aligning EEG signals to the time when a manipulated word is presented in a sentence. It is important to keep in mind that there is an EEG signal response to the presentation of each word in a sentence, and that the response to any given word is often influenced by responses to preceding words. Thus the dynamics of the EEG signal in response to any particular utterance are quite complicated. 

A set of linking hypotheses is necessary to relate power changes in the EEG signal—(and ultimately, ERPs)—to spectral coherence dynamics in interpretation trajectories. To illustrate these hypotheses we consider c- and s- system coherence trajectories and their first-derivatives in a canonical interpretation trajectory for \textit{Al drinks coffee}, shown below. As each word is perceived, sensory systems are excited (not shown). The specific pattern of excitation of sensory systems will in general be based on acoustic information of the stimuli (in the case of auditory stimuli) or visual information (in the case of graphemic/orthographic stimuli), but may also be influenced by “top-down” influences from previously excited conceptual and syntactic systems. Note that we have not developed a specific model of sensory systems in the o/el framework—such systems have generally been subsumed as part of the surroundings of c- and s- systems. Approximately 40-50ms after a stimulus, the excited sensory systems begin to exert forces on both c- and s-systems, causing them to become excited. The particular c- and s-systems which experience these forces necessarily depend on learned associations between sensory systems and c-/s- systems. For example, we have learned that the auditory or visual stimulus \textit{Al} excites an \{N\} s-system and [Al] c-system. Of course, other c- and s-systems may also be excited by the stimulus, particularly in cases of homophony, and the extent to which a given c- or s-system may be excited by a stimulus is conditioned by learning.

  When the stimulus \textit{Al} begins to activate \{N\} and [Al] systems, those systems begin to evolve toward an active state in which the individual neurons in the relevant populations are collectively oscillating. Thus there will be a transient period of time in which the auto-spectral coherence of each system is increasing. Recall that our microscale conception of the coherence process is that individual neuronal spikes within the population become more predictable, and on the macroscale this can be viewed as narrowing of a frequency distribution of spikes, i.e. the emergence of a more ordered state. The power spectra of c- and s-systems at selected points of time are shown in the figure. Both the widths and peak amplitudes of the spectra are assumed to be related to the coherence of the systems; the increase in coherence is modeled here as a first-order differential equation:  $\acute{{x}}=-a\left(x-{x}_{\mathit{max}}\right)$, where \textit{a} is a fixed growth rate parameter x\textsubscript{max} is an equilibrium which represents a maximal degree of coherence. 

  There are several key features of the trajectories to notice. First, although the s-systems and c-systems associated with a stimulus are activated at the same time, the c-system cannot reach an above ground state until after the s-system does. This reflects the hypothesis that excitation depends on the emergence of a cs-resonance. Second, there is “priming” for both c- and s-systems. For example, shortly after the \{V\} system is excited, an \{-N\} system is activated. Likewise, shortly after the [drinks] system is excited, a [coffee] system is activated. These priming effects are assumed to be pervasive, particularly for c-systems: presumably [drinks] activates a large number of c-systems (e.g. tea, whisky, etc.). Note that only priming of [coffee] is shown here in order to avoid visual clutter. A crucial consequence of the priming is that when the \textit{coffee} stimulus does occur, the \{-N\} and [coffee] systems already have some degree of coherence hence the change in coherence that is necessary to reach an above-ground state is smaller. This also results in a shorter period of time from the stimulus onset to the emergence of an above-ground [coffee]\{-N\} system. Finally, e-organization operations are shown here to occur after all three cs-systems have been excited; this aspect of the system trajectory is a somewhat arbitrary choice, rather than a necessity. It is possible that {\textbar}Al drinks{\textbar} could be e-organized in a more incremental fashion, prior to the emergence of the {\textbar}coffee \{-N\}{\textbar} system. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img141.png}
\caption{\missingcaption}
\label{fig:6:22}
\end{figure}
 

  The coherence trajectories shown for s-systems and c-systems above can be used to generate ERPs. Specifically, a short-time integration of the magnitude of the rate of change of coherence is hypothesized to correlate with power of the EEG signal. We emphasize that it is the \textit{magnitude of the rate of change of coherence}, rather than coherence itself, which is the relevant predictor. This follows from reasoning about how coherence is achieved on the microscopic scale. Coherence in a given population is reflected in the temporal distribution of spikes, or in other terms, their predictability or degree of order. Coherence is achieved over a period of time when the interactions between neurons in the population and interactions with other populations induce an excited state, which entails a narrow spectral peak. If a population takes longer to reach the excited state, there will be more spiking in the population. Furthermore, when the population is initially activated, differentiation interference experienced from other populations is expected to be larger, and the size of the population (number of neurons which interact) may be larger—the population will to a greater extent include or interact with neurons from populations which are associated with other systems. Thus in order for the population evolve to the excited state, microscopic interactions are necessary, and more of these interactions entails more neural spiking. The microscopic considerations therefore point to \textit{changes} in coherence as the most direct predictor of EEG power, rather than the excitation levels of systems. 

Changes in coherences in the trajectory above are the envelopes of the filled regions in the panels labelled s-system and c-system coherence. Power spectra of the integrated spiking rates of systems are shown at selected timepoints. These power spectra are understood to evolve continuously and require an integration window that is sufficiently large to resolve the lowest-frequency components of the population spiking rate. As discussed previously, the process of achieving a degree of coherence sufficient for excitation involves a narrowing of the frequency distribution. The widths and peak amplitudes of these spectra are assumed to be related to the coherence signals shown for the s-systems and c-systems. It is important to note that the coherence signals here are constructed from the simplifying assumption that coherence evolves as a linear system toward an equilibrium value—an important future endeavor is to develop a microscale model of population dynamics from which integrated spike rate can be derived, in turn allowing for derivation of coherence and order parameters (i.e. \textit{e} and θ). 

Another assumption depicted in the spectra is that the peak frequencies of the systems are initially different. The frequency locking process was modeled here with first-order systems that evolve toward a time-varying equilibrium that is the coherence-weighted average of the peak-frequencies of all of the s-systems and c-systems which are φ-coupled. Thus the peak frequency \{V\} of evolves toward a value that is the weighted average of the peak frequencies of \{+N\}, \{V\}, \{-N\}, and [drinks]; in contrast, the peak frequency of [drinks] evolves toward a value that is the weighted average of only \{V\} and [drinks]. Hence the frequency dynamics reflect the fundamental principle that s-systems are strongly φ-coupled to each other and resonate with a c-system. The overall effect of the frequency dynamics is that s-system peak frequencies evolve to a common frequency more quickly than c-system peak frequencies. This in turn has consequences for cross-spectral coherence: cross-spectral coherence of s-systems is expected to increase before cross-spectral coherence of c-systems.

  In order to facilitate the interpretation of ERP effects as changes in coherence, \textit{coherence-process signals} are calculated from the magnitude of the first derivative of coherence. This magnitude is low-pass filtered (using a rectangular-window moving average), which approximates a short-time integration of changes in coherence. The resulting signals are called “coherence-process signals” because they arise from the process of coherence; they should not be confused with spectral or cross-spectral coherence. Several different coherence-process signals are shown in the bottom panel of the figure. The s-system coherence process signals are summed over the \{+N\}, \{V\}, and \{-N\} systems; likewise the c-system signals are summed over [Al], [drinks], and [coffee] systems. In theory, other coherences are also relevant, particularly the cross-spectral coherence between s-systems and c-systems, and between cs-systems. However, cross-spectral coherence cannot be calculated without phase information, which in turn cannot be calculated without a model that generates spike-rate time series. In the absence of such a model, cross coherences are approximated by the products of power spectra. The cross-coherence-process signals shown in the figure are thus low-pass filtered derivatives of the integration over frequency of products of spectra, summed over the relevant pairs of systems. Specifically, the s-system cross-coherence-process signal is the sum over the cross-coherence-process signals of \{+N\}\{V\}, \{V\}\{-N\}, and \{N\}\{-N\}; the c-system cross-coherence-process signal is the sum over the cross-coherence-process signals of [Al][drinks], [drinks][coffee], and [Al][coffee]; and the c-s cross-coherence-process signal is the sum over the cross-coherence-process signals of \{+N\}[Al], \{V\}[drinks], and \{-N\}[coffee]. 

In general, all of the coherence process signals may contribute to the EEG signal, but for current purposes we will focus on only one or two such signals to analyze ERP effects. Ultimately, the set of assumptions and approximations in the above model should be viewed together as an ansatz, an educated guess which may or may not be verified by its results. As we see below, the results are in many ways consistent with observations.

\subsection{Relations between coherence and ERP patterns}

The first ERP we analyze is the ELAN (early left-anterior negativity), which is a negative peak observed from 100-300 ms after stimulus presentation. The ELAN is associated primarily with identification of the syntactic category of a word (\citealt{Friederici2002,HahneFriederici1999,SteinhauerDrury2012}). The main empirical finding is that a word whose syntactic category is relatively unexpected results in an increase in the amplitude of the peak, compared to words whose syntactic category is relatively expected, given prior context. For example, in (a) below, a word that is a noun such as \textit{coffee} is expected given that the preceding word \textit{drinks} is a transitive verb; in (b) the preposition \textit{on} is less expected.

\ea
\ea Al drinks coffee.         category matches expectation [F0E0?] smaller ELAN
\ex Al drinks *on coffee.    category mismatches expectations [F0E0?] larger ELAN
\z
\z

In o/el terms, activation of a less expected system—e.g. the \{P\} s-system in sentence (b)—elicits a larger negative peak than activation of a more expected system—e.g. the \{-N\} s-system in sentence (a). This can be described as a priming effect: the word drinks excites a \{V\} s-system which resonates with [drink], and also activates a \{-N\} system which will typically will resonate with a subsequently activated c-system. This priming effect is shown in the {\figurebelow} where \{-N\} is activated shortly after \{V\}. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img142.png}
\caption{\missingcaption}
\label{fig:6:23}
\end{figure}
 

There are several reasons why the coherence-process signal after presentation of the mismatching category \{P\} is greater than the signal when the expected \{N\} is presented. Because the \{-N\} system is already activated, a smaller increase in coherence is required to achieve an excited state when \textit{coffee} is presented compared to the increase required for the \{P\} system to reach a coherent state when the preposition \textit{on} is presented. Hence one source of the ERP effect is that excitation of \{P\} requires a greater change of coherence, and as elaborated above, coherence-process signals reflect an integration of changes in coherence. Another possible source of the ERP effect may be interference between \{P\} and \{-N\}. This interference is expected to slow achievement of coherence of \{P\} and possibly decrease the coherence of \{-N\}—these effects are illustrated in the figure as well. An increase in the period of time over which coherence is achieved, and a change in the coherence of the already active \{-N\}, both contribute to a larger coherence-process signal.

  The next ERP we consider is the N400, which is a negative peak observed from 300-500 ms after stimulus presentation. The amplitude of the N400 is inversely correlated with the extent to which a word is semantically expected (\citealt{FedermeierLaszlo2009,Friederici2002,KutasFedermeier2011}). For example, the c-system [coffee] which is activated by utterance (a) below is more expected than the c-system [toothpaste] activated by (b). The word \textit{coffee} has a greater cloze probability than \textit{toothpaste} in this context, i.e. a greater likelihood of completing the sentence \textit{Al drinks}.

\ea
\ea Al drinks coffee.         concept less consistent with expectations [F0E0?] smaller N400
\ex Al drinks toothpaste.    concept more consistent with expectations [F0E0?] larger N400
\z
\z

The analysis of the N400 is directly parallel to the analysis of the ELAN: [coffee] is primed by [drinks] to a greater extent than [toothpaste], and hence the achievement of coherence of [toothpaste] requires a greater change in coherence than [coffee]. The key difference between the ELAN and the N400 is that the ELAN arises from activation of s-systems, while the N400 arises from activation of c-systems. As described above, c-system excitation is delayed relative to s-system excitation, because c-system excitation requires resonance with an excited s-system.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img143.png}
\caption{\missingcaption}
\label{fig:6:24}
\end{figure}
 

The N400 effect does not require a sentential context and is influenced by a number of factors which include semantic category membership, word frequency, and neighborhood density (\citealt{KutasFedermeier2011,LauEtAl2008}). In lists of words in which a semantic category expectancy is generated, a word whose semantic category deviates from the expectation will induce a larger N400. For example, in the utterances in \REF{ex:6:1bisa} and \REF{ex:6:1bisb} below, \textit{toothpaste} will induce a larger N400 than \textit{wine}. The N400 is sensitive to word frequency as well: in the utterances in \REF{ex:6:2bis} \textit{ouzo} will induce a larger N400 than \textit{coffee}. In both cases, it is sensible to assume that prior to presentation of the stimulus \textit{wine}, a [wine] system is already active to some degree, and hence a smaller change in coherence of [wine] occurs post-stimulus than in cases where the stimulus-activated c-system has been pre-activated to a lesser degree. In other words, the frequency effect arises because [drinks] activates (“primes”) a higher-frequency c-system like [wine] to a greater extent than a lower-frequency c-system like [ouzo].

\ea\label{ex:6:1bis}
\ea\label{ex:6:1bisa} coffee, tea, whisky, wine
\ex\label{ex:6:1bisb}  coffee, tea, whisky, toothpaste
\z
\z

\ea\label{ex:6:2bis}
\ea\label{ex:6:2bisa} Al drinks wine.
\ex\label{ex:6:2bisb} Al drinks ouzo.
\z
\z

  The interpretation of neighborhood density effects on the N400 is somewhat different from the effects discussed above. A word with a denser neighborhood will induce a larger N400 than a word with a sparser neighborhood \citep{HolcombEtAl2002,MüllerEtAl2010}). This effect should be understood to arise because stimuli with denser neighborhoods will activate more c-systems than those with sparser neighborhoods. When more c-systems are active, there is more competition between c-systems for a cs-resonance and the c-systems interfere with each other to a greater extent. Hence it will take longer for a coherent cs-resonance to emerge than in a condition where fewer c-systems are primed. 

  An interesting finding regarding the N400 is that it is often insensitive to negation \citep{KutasFedermeier2011}. Hence N400s for \textit{toothpaste} are similar in \textit{Al drinks toothpaste} and \textit{Al does not drink toothpaste}. This suggests that negation and possibly quantification in general does not influence the priming effects that modulate the amplitude of the N400. This raises questions regarding relational meaning experiences which involve negation and quantification; such meaning experiences have not yet been analyzed in the o/el framework.

  In the same time period as the N400, a left anterior negativity (LAN) is sometimes observed in response to morphosyntactic agreement violations (\citealt{Friederici2002,GunterEtAl2000,KutasFedermeier2011,OsterhoutHolcomb1992}). For example, \textit{the students drinks coffee}, where the verbal number agreement mismatches the number of the subject argument, will elicit a greater N400 than \textit{the student drinks coffee}. This suggests that excitation of grammatical s-systems (i.e. \{\textsc{number}\}, \{\textsc{person}\}, \{\textsc{tense}\} etc.) occurs later in time than excitation of lexical s-systems (i.e. \{N\}, \{V\}, \{P\}, etc.), where mismatches are associated with the ELAN. This is consistent with the notion that grammatical s-systems must be coupled to an excited lexical s-systems in order to become excited themselves. Along these lines, consider that the utterance \textit{the}, which excites only \{D\}[\textsc{definite}], does not give rise to a coherent configuration: there is no lexical cs-resonance for \{D\}[\textsc{definite}] to couple with. It should be noted, however, that agreement violations do not always appear to elicit a LAN effect, but instead elicit may a later effect called the P600, which we consider next. In these cases, both prior syntactic and conceptual excitation may be required for effects to manifest in coherence-process signals.

  The P600 is a positive EEG signal occurring from 600-1000 ms after a stimulus. The P600 has a centro-parietal location, as opposed to the left-anterior locations of the ELAN and LAN. It has been associated with syntactic violations, processes of reanalysis and repair (as in garden-path sentences), and syntactic complexity \citep{Friederici2002}. Although some researchers view the P600 as a language-specific ERP component, others have argued that the P600 is not distinct from the more general P3, an ERP that is associated with attention-related reorientation behavior \citep{SassenhagenBornkessel-Schlesewsky2015}. This raises the question of whether in the o/el model the P600 (or P3) can be understood differently from the ELAN, N400, and LAN, all of which are attributable to priming, i.e. pre-stimulus activation of systems below the excitation threshold.

  To address this, lets consider a garden path sentence such as \textit{Al drinks coffee and tea is brewing}. Lets assume that in the garden-path interpretation there is a state in which an {\textbar}Al drinks coffee{\textbar} configuration is excited, followed by a state in which an {\textbar}Al drinks tea{\textbar} configuration is excited. Upon occurrence of the stimuli \textit{is brewing}, the relevant cs-systems [be]\{\textsc{aux}\} and [brew]\{V\} become active, but because [tea]\{N\} is already coupled to [drink]\{V\}, it is not able to couple stably to [brew]\{V\}. This results in [brew]\{V\} failing to achieve coherence. We conjecture that this non-coherence induces a “repair” process, which involves e-operations which ground some or all systems and subsequent reorganization operations. If the reorganization leads to a grammatically coherent trajectory, the repair is successful. However, the grounding and reorganization e-operations that occur during the repair result in many changes in spectral and cross-spectral coherence, which are manifested as changes in EEG power. 

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/Tilsen-img144.png}
\caption{\missingcaption}
\label{fig:6:25}
\end{figure}
 

One question we might ask is why the P600 has a different spatial distribution and sign than other ERPs. Consider that there are several differences in the mechanisms which cause coherence changes during a repair, compared to those associated with priming effects. For starters, the ELAN and N400 are associated with the timecourse of excitation of cs-systems, which occurs prior to the emergence of a stable configuration; this excitation does not necessitate any e-organization. In contrast, the P600 is associated with e-operations on already-excited or already-activated systems, and hence is expected to occur later. Secondly, it may be useful to construct \textit{coherence-response systems}, which are systems which become active when cs-states are non-coherent. Coherence response systems provide a mechanism for “monitoring” the state of the system, and likely play a role in shaping grammaticality intuitions discussed earlier. It would not be surprising if coherence response systems have a different spatial distribution than cs-systems, but the imprecision in spatial localization of ERP generators warrants caution in drawing inferences in this regard.

\subsection{Toward a new vocabulary of psycholinguistic analysis}

The o/el framework offers an alternative vocabulary for interpreting psycholinguistic observations of behavior. There are several advantages of this vocabulary: (i) It brings temporal phenomena to the fore with a conceptual model that is focused on dynamics. (ii) It avoids potentially misleading anthropomorphizations. (iii) It provides a basis for a more specific conception of \textit{information}. (iv) It avoids conceptual dissonance that arises in describing phenomena which necessitate simultaneous reference to incompatible structures.

To illustrate these advantages, lets consider how ERP effects are typically described in psycholinguistic literature. Such effects are commonly attributed to “mismatches,” “processing difficulty,” or “reanalysis/repair” (see e.g. \citealt{Friederici2002,KutasFedermeier2011}). For instance, the ELAN is understood as the result of a mismatch between the syntactic category of a stimulus and the expected category, which occurs in a process of word category “identification”. The N400 is understood as an index of difficulty in “processing” which occurs in the “integration of semantic and syntactic information”. The P600 is understood as an index of complexity or the need for “reanalysis”.

Psycholinguistic studies do not always provide more specific details regarding what these terms mean in the context of a conceptual model of syntax. Basic questions arise which call for detailed answers: what is “processing”? What does it mean to “identify” a syntactic category. What form does the “expectation” of a category take? What is a “category”, anyway? Object-based conceptions do not readily help us understand the behavioral manifestations of processing, because objects are atemporal. In contrast, the systems of the o/el framework evolve in time and are characterized in terms of states. Thus “identification” of a category can be understood as a state space trajectory in which sensory systems activate a conceptual and syntactic systems, and in which those systems subsequently evolve from an active state to an excited state, via coupling mechanisms. The microscale conceptual model further informs our understanding of the trajectory by allowing us to think of the evolution as emergence of spectrally coherent collective oscillations in neural populations. The \textit{trajectory} IS the “processing,” and there are no categories, but rather, \textit{systems}.

The concept of “processing information” is potentially misleading for a couple reasons. First, \textit{processing} evokes a computational interpretation of phenomena, and most computational models impose temporally discrete operations on system states. The states of systems we have constructed in the o/el framework—particularly in pre-stable epochs of production and interpretation—are understood to evolve continuously in time, and this evolution should not be viewed as the consequence of discrete operations. Of course, discrete computations applied in the limit of infinitesimally small time increments provides an effectively continuous approximation to system dynamics, but computational interpretations in linguistic theories rarely adopt this infinitesimal limit construal. Thus use of the word \textit{processing} has the potential to evoke a counterproductive discretization of time. Second, the computational interpretation tends to evoke symbols, because many computational models of language are developed to manipulate symbolic representations, rather than states defined in continuous dimensions. Because symbols are objects, any interpretation of behavior which evokes them will lead to many of the problems of the object metaphor which we have discussed in this book. 

In a deeper sense, the interpretation of information processing as symbol manipulation unnecessarily obscures the nature of the state space and thereby leads to an inadequate conception of \textit{information}. What do people mean when they say that the brain “processes information”? The word \textit{information} seems to be often used in a non-technical sense, and is rarely defined in a rigorous manner. The tenets of information theory \citep{Shannon1948} hold that information is \textit{produced} when a previously undetermined (or unobserved) system state is determined (or observed). The information produced by the determination process is measured as the change in entropy (H) of the system from before determination to after determination. The entropy is the negative sum of the log probabilities of states, weighted by their probabilities, as shown in the equation below. Thus information is entropy lost in the determination of a system state.

  Information produced = Entropy before – Entropy after

\begin{equation*}
H=-\sum _{i}{{p}_{i}\log \left({p}_{i}\right)={-p}_{1}\log \left({p}_{1}\right){-p}_{2}\log \left({p}_{2}\right)-{\dots}-{p}_{n}\log \text{⁡}\left({p}_{n}\right)}
\end{equation*}

In the case of a system which generates equiprobable discrete states, such as a coin flip or a random selection of a character from the alphabet, the information that is produced from each flip or character selection (i.e. from the determination process), increases when there are more possible states: hence there is more information produced by selecting a character of the alphabet than by flipping a coin. In both cases, the entropy after determination is zero—the system state is fully determined, but the number of possible states before determination is greater for the alphabet, which has 26 possible states, than for the coin, which has only 2. The same reasoning can be generalized to continuous variables, in which case it is the probability-weighted volume of the state space before determination that matters for calculating the information that is produced. It is crucial to recognize that a state of the system itself does not “have information,” but rather, information is something that is “gained” by a reduction of volume of the state space or “lost” by an increase of volume of the state space. Furthermore, the first terms in the products in the entropy equation, which are probabilities of states (\textit{p}\textsubscript{i}), are weighting terms which specify how much each sub-volume of state space contributes to the total entropy associated with the space. The information gained by determination of a state is maximal when those probabilities are uniformly distributed over the space.

How does the technical understanding of information gel with the o/el conception of a state space trajectory? The o/el analysis might seem to imply that no information can ever be lost or gained: the system state is always determined, and evolves according to deterministic laws; thus there is no determination process which allows for a change in entropy. However, consider that our analyses always partition the full system state into systems and a surroundings: it is only the systems whose states are always determined; the surroundings state is never determined. Hence entropy can be transferred from systems to the surroundings. Indeed, this is exactly what happens on the microscale when a c-system or s-system becomes active: the entropy of the population decreases, by means of being transferred to the surroundings. This entails a reduction in the number of accessible microstates of the system, but not of the universe.

Alternatively, we can say that the order (i.e. negentropy, see \citealt{Schrödinger1944}) of the system increases. Thus information has been produced \textit{locally}, i.e. in the region of state space which is relevant to describing the system. This local increase is always offset by an increase of entropy in the surroundings, and according to the second law of thermodynamics is always greater than or equal to the local decrease. It is more appropriate, in o/el terms, to think of “information processing” as local increase or decrease of order in systems. The advantages of this perspective are that we allow for a more detailed accounting of the temporal evolution of probability mass in state space, and are better able to see the connection between information and our analytical choices in partitioning the universe into systems vs. surroundings. 

Another advantage of the o/el conception is that “expectation” or “prediction” of a category or meaning is not accomplished with ad hoc, anthropomorphic mechanism. Instead, a more phenomenologically neutral description is available in which the activation of a system induces activation of other systems which are likely to become active in the future. This mechanism allows us to understand ELAN, LAN, and N400 effects just as readily as conventional vocabularies. “Prediction” is problematic because it evokes a potentially misleading anthropomorphization of the system. The verb \textit{predict} entails an animate agent (cf. \textit{Bo predicted Al would drink coffee} vs. \textsuperscript{?}\textit{The table predicted Al would drink coffee}). There is no theoretical necessity to conceptualize the system as animate, or as the sort of entity which “makes predictions”. Rather, we say that the system state evolves such that its location in state space tends to move closer to states which are statistically more likely to arise in the future. This aspect of the system is a consequence of supra-utterance scale “learning” mechanisms which are viewed microscopically as changes in within- and between-population interactions.

The conventional vocabulary often employs terms like \textit{reanalysis} or \textit{repair}. But what is being reanalyzed, and what entity is doing the reanalyzing? In some cases authors propose to interpret these terms with object-based representations. For example, reanalysis has been described with substitution and adjunction operations on elementary trees in a tree-adjoining grammar conception \citep{FFerreiraEtAl2004}. Thus reanalysis involves the unmerging of some objects, while keeping those objects present, in order to re-merge them subsequently. One problem with this sort of conceptualization is that is does not predict any inherent cost for the “floating structures” or “unintegrated objects” which arise in such models, nor for the operations which create them. Why should object structures which are not connected to other object structures be problematic? It is certainly possible in such models to stipulate that unmerged objects give rise to processing difficulty, but this does not address the question of \textit{why} the processing difficulty arises, or what “processing” is in a mechanistic sense.

The o/el framework provides greater clarity regarding what processing is, what “unintegrated structures” are, and why the reanalysis that produces them leads to behavioral effects such as increased P600, slowed reading times, and/or saccadic backtracking. In conventional approaches, unintegrated structures are structures of objects that are not merged into some other structure which is already present. Instead of imagining of objects in space, the o/el conception posits systems which can be characterized by their spectral coherence and coupling to other systems. Unintegrated structures are cs-systems which are (i) not coupled to other cs-systems and (ii) are not spectrally coherent. A consequence of these conditions is that these systems experience stronger interference from other systems, and are therefore less stable. The repair process, as described in our analysis of the P600, involves the application of grounding and subsequent reorganization operations. This allows for alternative φ configurations to arise, and subsequently for a grammatically coherent interpretation trajectory to occur. The initial instability and the reorganization operations are associated with changes in spectral coherence which manifest in ERPs. We have furthermore conjectured that there may be \textit{coherence response systems} which respond to noncoherent states by inducing reorganizations. Along these lines, a sensible endeavor is to develop a model of oculomotor control in which coherence response systems influence reading behavior; this will allow for reading time and saccadic backtracking to be modeled in the framework.

One of the most fundamental problems with object-based conceptions of psycholinguistic phenomena is that they do not lend well to reasoning about the “parallel” activation of systems. Consider the garden path utterance in \REF{ex:6:1ter} below. The interpreter may excite a {\textbar}dressed baby{\textbar} configuration, but this leads to a non-coherent state because [played]\{V\} cannot participate in a φ configuration with a \{+N\} system. The experience of non-coherence may then induce reorganizations which lead to a coherent trajectory involving {\textbar}Al dressed (himself){\textbar} and {\textbar}baby played{\textbar} configurations. Psycholinguistic studies have found evidence that the garden-pathed relational meaning of {\textbar}dressed baby{\textbar} may “linger,” based on the observation that interpreters will sometimes answer “yes” to question \REF{ex:6:2tera} \citep{SlatteryEtAl2013}, indicating that the originally engaged configuration remains in memory after the repair.

\ea{ex:6:1ter}
{While Al dressed the baby played in the crib.}
\z

\ea
\ea \label{ex:6:2tera} {Did Al dress the baby?}
\ex \label{ex:6:2terb }{Did Al dress himself?}
\z
\z

The issue here is how to conceptualize working memory and “lingering structures”. As we explored earlier, a standard mapping of the object metaphor is that two linguistic units cannot occupy the same position in a structure, just as two different objects cannot occupy the same space. Thus in order to adapt a conventional conceptualization of structure to this sort of phenomenon, it is necessary to circumvent violations of the standard mapping. To wit, \citet{SlatteryEtAl2013} describe an account in which there is an “overlay function” which allows a lingering structure to be ‘present “underneath”’ the new structure. The fact that the authors scare-quote “underneath” suggests a subtle discomfort with the spatial implications of this metaphor, which are dissonant with the conventional conception. The lingering structure must be underneath the new one because objects cannot occupy the same space. But what is the nature of this new “space” in which other structures of objects can be “present”?

It is not the notion that interpretation involves parallel (i.e. simultaneous) activation of systems that is the problem, but rather, the notion that working memory is a space for objects. The problems are easily resolved when we see that our use of the term \textit{working memory} refers to certain aspects of a state (or dimensions of a state space), rather objects occupying space. A working memory state can be defined in the same sort of φ/e state space as the one in which production and interpretation trajectories are defined. A “lingering structure” is a set of activated cs-resonances, which by virtue of being in an active state increase the likelihood that those systems can subsequently form a stable configuration.

The o/el framework thus provides an alternative vocabulary that, because of its emphasis on the dynamics of systems and construction of state spaces, clarifies our conception of information, avoids anthropomorphization, and links our conceptual model of language more directly to behavioral observations. The disadvantage of the alternative vocabulary is that it is unfamiliar. The only way to change that is to practice using the vocabulary, and thereby explore its utility for conceptualizing phenomena. To that end, the next chapter examines several syntactic phenomena which have received much focus from the conventional perspective.  

